{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNh0UUpkKgER"
   },
   "source": [
    "\n",
    "###Automated stock trading using FinRL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK_Mjqc5KRUN"
   },
   "source": [
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "Action: The action space describes the allowed actions that the agent interacts with the environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s', i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
    "\n",
    "State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "Environment: Dow 30 consituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyPN-xFjKvfd"
   },
   "source": [
    "Install all the packages through FinRL library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16341,
     "status": "ok",
     "timestamp": 1738147776086,
     "user": {
      "displayName": "Hamdan Zoghbor",
      "userId": "16799748073692251556"
     },
     "user_tz": -240
    },
    "id": "5puSWUvXBBBr",
    "outputId": "a0e47d99-a16e-4550-9e2b-762a914af452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
      "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-s2lpnqfe\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-s2lpnqfe\n",
      "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 3c915e7f05f0b331d2e842aca5de0e36be3c1bb3\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git (from finrl==0.3.6)\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-s86rqq9k/elegantrl_8ca2ce357d7143428158e74fa850db6b\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-s86rqq9k/elegantrl_8ca2ce357d7143428158e74fa850db6b\n",
      "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-s2lpnqfe\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-s2lpnqfe\n",
      "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 3c915e7f05f0b331d2e842aca5de0e36be3c1bb3\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git (from finrl==0.3.6)\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-s86rqq9k/elegantrl_8ca2ce357d7143428158e74fa850db6b\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-s86rqq9k/elegantrl_8ca2ce357d7143428158e74fa850db6b\n",
      "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 2fa34dd9236498beada8d8443d927970a9de1f7f\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting alpaca-py<0.38,>=0.37 (from finrl==0.3.6)\n",
      "  Using cached alpaca_py-0.37.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting alpaca-py<0.38,>=0.37 (from finrl==0.3.6)\n",
      "  Using cached alpaca_py-0.37.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting alpaca-trade-api<4,>=3 (from finrl==0.3.6)\n",
      "  Using cached alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting ccxt<4,>=3 (from finrl==0.3.6)\n",
      "  Using cached ccxt-3.1.60-py2.py3-none-any.whl.metadata (108 kB)\n",
      "Collecting exchange-calendars<5,>=4 (from finrl==0.3.6)\n",
      "  Using cached exchange_calendars-4.9-py3-none-any.whl.metadata (37 kB)\n",
      "  Using cached exchange_calendars-4.9-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting jqdatasdk<2,>=1 (from finrl==0.3.6)\n",
      "  Using cached jqdatasdk-1.9.7-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pyfolio<0.10,>=0.9 (from finrl==0.3.6)\n",
      "  Using cached pyfolio-0.9.2.tar.gz (91 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyportfolioopt<2,>=1 (from finrl==0.3.6)\n",
      "  Using cached pyfolio-0.9.2.tar.gz (91 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyportfolioopt<2,>=1 (from finrl==0.3.6)\n",
      "  Using cached pyportfolioopt-1.5.6-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting ray<3,>=2 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading ray-2.42.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Downloading ray-2.42.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting scikit-learn<2,>=1 (from finrl==0.3.6)\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting selenium<5,>=4 (from finrl==0.3.6)\n",
      "  Using cached selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting selenium<5,>=4 (from finrl==0.3.6)\n",
      "  Using cached selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting stable-baselines3>=2.0.0a5 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Using cached stable_baselines3-2.6.0a0-py3-none-any.whl.metadata (4.8 kB)\n",
      "  Using cached stable_baselines3-2.6.0a0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting stockstats<0.6,>=0.5 (from finrl==0.3.6)\n",
      "  Using cached stockstats-0.5.4-py2.py3-none-any.whl.metadata (26 kB)\n",
      "Collecting webdriver-manager<5,>=4 (from finrl==0.3.6)\n",
      "  Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting webdriver-manager<5,>=4 (from finrl==0.3.6)\n",
      "  Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting wrds<4,>=3 (from finrl==0.3.6)\n",
      "  Using cached wrds-3.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting yfinance<0.3,>=0.2 (from finrl==0.3.6)\n",
      "  Using cached yfinance-0.2.52-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting pandas>=1.5.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting requests<3.0.0,>=2.30.0 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sseclient-py<2.0.0,>=1.7.2 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting websockets>=10.4 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting numpy>=1.11.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting pandas>=1.5.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting requests<3.0.0,>=2.30.0 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sseclient-py<2.0.0,>=1.7.2 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting websockets>=10.4 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting numpy>=1.11.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting urllib3<2,>1.24 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting websocket-client<2,>=0.56.0 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting websockets>=10.4 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading msgpack-1.0.3.tar.gz (123 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiohttp<4,>=3.8.3 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading aiohttp-3.11.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting websockets>=10.4 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading msgpack-1.0.3.tar.gz (123 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aiohttp<4,>=3.8.3 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading aiohttp-3.11.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting PyYAML==6.0.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting deprecation==2.1.0 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (24.2)\n",
      "Requirement already satisfied: setuptools>=60.9.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.6) (75.8.0)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (24.2)\n",
      "Requirement already satisfied: setuptools>=60.9.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.6) (75.8.0)\n",
      "Collecting certifi>=2018.1.18 (from ccxt<4,>=3->finrl==0.3.6)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting cryptography>=2.6.1 (from ccxt<4,>=3->finrl==0.3.6)\n",
      "  Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "  Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting aiodns>=1.1.1 (from ccxt<4,>=3->finrl==0.3.6)\n",
      "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting yarl>=1.7.2 (from ccxt<4,>=3->finrl==0.3.6)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Collecting pyluach (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
      "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting toolz (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tzdata (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tzdata (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting korean_lunar_calendar (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
      "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.17.0)\n",
      "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from jqdatasdk<2,>=1->finrl==0.3.6) (1.17.0)\n",
      "Collecting SQLAlchemy>=1.2.8 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
      "  Downloading SQLAlchemy-2.0.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "  Downloading SQLAlchemy-2.0.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting pymysql>=0.7.6 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting thriftpy2!=0.5.1,>=0.3.9 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
      "  Downloading thriftpy2-0.5.2.tar.gz (782 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.3/782.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (8.32.0)\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting thriftpy2!=0.5.1,>=0.3.9 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
      "  Downloading thriftpy2-0.5.2.tar.gz (782 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.3/782.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pyfolio<0.10,>=0.9->finrl==0.3.6) (8.32.0)\n",
      "Collecting matplotlib>=1.4.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pytz>=2014.10 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pytz>=2014.10 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting scipy>=0.14.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "  Downloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting seaborn>=0.7.1 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting empyrical>=0.5.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cvxpy>=1.1.19 (from pyportfolioopt<2,>=1->finrl==0.3.6)\n",
      "  Downloading cvxpy-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cvxpy>=1.1.19 (from pyportfolioopt<2,>=1->finrl==0.3.6)\n",
      "  Downloading cvxpy-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting ecos<3.0.0,>=2.0.14 (from pyportfolioopt<2,>=1->finrl==0.3.6)\n",
      "  Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "  Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
      "Collecting plotly<6.0.0,>=5.0.0 (from pyportfolioopt<2,>=1->finrl==0.3.6)\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting click>=7.0 (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting filelock (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting aiosignal (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting prometheus-client>=0.7.1 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting smart-open (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading virtualenv-20.29.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading virtualenv-20.29.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "  Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pyarrow>=9.0.0 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading pyarrow-19.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "  Downloading pyarrow-19.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting fsspec (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn<2,>=1->finrl==0.3.6)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn<2,>=1->finrl==0.3.6)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting trio~=0.17 (from selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from selenium<5,>=4->finrl==0.3.6) (4.12.2)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting trio~=0.17 (from selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from selenium<5,>=4->finrl==0.3.6) (4.12.2)\n",
      "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting torch<3.0,>=2.3 (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting cloudpickle (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting opencv-python (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting pygame (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: psutil in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.9.0)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: psutil in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (5.9.0)\n",
      "Collecting tqdm (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting rich (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting ale-py>=0.9.0 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "  Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting pillow (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting python-dotenv (from webdriver-manager<5,>=4->finrl==0.3.6)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting python-dotenv (from webdriver-manager<5,>=4->finrl==0.3.6)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting numpy>=1.11.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting packaging (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting psycopg2-binary<2.10,>=2.9 (from wrds<4,>=3->finrl==0.3.6)\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting scipy>=0.14.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lxml>=4.9.1 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
      "  Downloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.3.6)\n",
      "  Downloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.3.6)\n",
      "Collecting frozendict>=2.3.4 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
      "  Downloading frozendict-2.4.6-py311-none-any.whl.metadata (23 kB)\n",
      "  Downloading frozendict-2.4.6-py311-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
      "  Downloading peewee-3.17.9.tar.gz (3.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4>=4.11.1 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading peewee-3.17.9.tar.gz (3.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4>=4.11.1 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting html5lib>=1.1 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting th (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.6)\n",
      "  Downloading th-0.4.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Downloading th-0.4.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.6)\n",
      "  Downloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "  Downloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.6)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6)\n",
      "  Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "  Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting osqp>=0.6.2 (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
      "  Downloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "  Downloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting clarabel>=0.5.0 (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
      "  Downloading clarabel-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "  Downloading clarabel-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting scs>=3.2.4.post1 (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
      "  Downloading scs-3.2.7.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "  Downloading scs-3.2.7.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pandas-datareader>=0.2 (from empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading pandas_datareader-0.10.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading pandas_datareader-0.10.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium<1.1.0,>=0.29.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting webencodings (from html5lib>=1.1->yfinance<0.3,>=0.2->finrl==0.3.6)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: decorator in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.14.3)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: decorator in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (5.14.3)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading fonttools-4.55.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "  Downloading fonttools-4.55.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.9.0.post0)\n",
      "Collecting tenacity>=6.2.0 (from plotly<6.0.0,>=5.0.0->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.6)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Cython>=3.0.10 (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6)\n",
      "  Using cached Cython-3.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting ply<4.0,>=3.4 (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6)\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Cython>=3.0.10 (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6)\n",
      "  Using cached Cython-3.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting ply<4.0,>=3.4 (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6)\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "Collecting networkx (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading rpds_py-0.22.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "  Downloading rpds_py-0.22.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting wrapt (from smart-open->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting niltype<2.0,>=0.3 (from th->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.6)\n",
      "  Downloading niltype-1.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "  Downloading niltype-1.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.8.4)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.8.4)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting qdldl (from osqp>=0.6.2->cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
      "  Downloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.13)\n",
      "  Downloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.13)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from stack_data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from stack_data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from stack_data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.3)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.6)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from stack_data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from stack_data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from stack_data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6) (0.2.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading alpaca_py-0.37.0-py3-none-any.whl (121 kB)\n",
      "Downloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ccxt-3.1.60-py2.py3-none-any.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading exchange_calendars-4.9-py3-none-any.whl (198 kB)\n",
      "Downloading jqdatasdk-1.9.7-py3-none-any.whl (77 kB)\n",
      "Downloading pyportfolioopt-1.5.6-py3-none-any.whl (62 kB)\n",
      "Downloading ray-2.42.0-cp311-cp311-manylinux2014_x86_64.whl (67.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading stable_baselines3-2.6.0a0-py3-none-any.whl (184 kB)\n",
      "Downloading stockstats-0.5.4-py2.py3-none-any.whl (21 kB)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading wrds-3.2.0-py3-none-any.whl (13 kB)\n",
      "Downloading yfinance-0.2.52-py2.py3-none-any.whl (108 kB)\n",
      "Downloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
      "Downloading aiohttp-3.11.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cvxpy-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "Downloading frozendict-2.4.6-py311-none-any.whl (16 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading SQLAlchemy-2.0.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:08\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading virtualenv-20.29.1-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading th-0.4.1-py3-none-any.whl (12 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading alpaca_py-0.37.0-py3-none-any.whl (121 kB)\n",
      "Downloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ccxt-3.1.60-py2.py3-none-any.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading exchange_calendars-4.9-py3-none-any.whl (198 kB)\n",
      "Downloading jqdatasdk-1.9.7-py3-none-any.whl (77 kB)\n",
      "Downloading pyportfolioopt-1.5.6-py3-none-any.whl (62 kB)\n",
      "Downloading ray-2.42.0-cp311-cp311-manylinux2014_x86_64.whl (67.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading stable_baselines3-2.6.0a0-py3-none-any.whl (184 kB)\n",
      "Downloading stockstats-0.5.4-py2.py3-none-any.whl (21 kB)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading wrds-3.2.0-py3-none-any.whl (13 kB)\n",
      "Downloading yfinance-0.2.52-py2.py3-none-any.whl (108 kB)\n",
      "Downloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
      "Downloading aiohttp-3.11.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading ale_py-0.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cvxpy-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "Downloading frozendict-2.4.6-py311-none-any.whl (16 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading SQLAlchemy-2.0.37-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:08\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading virtualenv-20.29.1-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading th-0.4.1-py3-none-any.whl (12 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Downloading clarabel-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached Cython-3.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading fonttools-4.55.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading niltype-1.0.2-py3-none-any.whl (5.3 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
      "Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "Downloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Downloading clarabel-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached Cython-3.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading fonttools-4.55.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading niltype-1.0.2-py3-none-any.whl (5.3 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
      "Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "Downloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.22.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "Downloading scs-3.2.7.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.22.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "Downloading scs-3.2.7.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: finrl, msgpack, pyfolio, elegantrl, empyrical, peewee, thriftpy2\n",
      "  Building wheel for finrl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for finrl: filename=finrl-0.3.6-py3-none-any.whl size=4695552 sha256=5a54289f77251e60544398dc46c96874f7c26a2a1588b6907ff2a5f9f4e450f1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jou107u0/wheels/22/04/d2/8ee1f0ed6a91622a6548d244772ae124a9b3795372817286a0\n",
      "  Building wheel for msgpack (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for msgpack: filename=msgpack-1.0.3-cp311-cp311-linux_x86_64.whl size=15741 sha256=3715cf18c5e8e31984f425f0d91ecb5e0d13cf044dce41c2d314b193e4dd9255\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/f6/35/da/ed9b26b510235e00e3a3c3bab7bad97b59214729662255ab3d\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88720 sha256=993c592e0b650f5f9e00bc4fa3434fc7a47f277ed734ac6aabfac8305913ef0b\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/f9/af/9e/7c343b822164a3147a3d395a1bcd05041c520a3bc6398fe88e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for elegantrl: filename=ElegantRL-0.3.10-py3-none-any.whl size=271988 sha256=8992bab4411eec05224a4d6778cafcf36a4b51082ba66752a3c4d8b94e115479\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jou107u0/wheels/9a/77/4d/6284111037b2dd64af9ef18d4d600d9c185cc2f6f09704e896\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39807 sha256=04ae75ee31963f0564083db2e48c132942893a62b24a7c2885a98d70148fc776\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/ac/1d/58/a7ae5ef5c8de7c4b769f24c2584f4706564921f031b16b9cb6\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.9-cp311-cp311-linux_x86_64.whl size=300871 sha256=2766ffb428c30f76106c5f9b4099a15b5d6ac28d02873a28da093e4599b189ff\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/f4/14/e4/50c88c865833085aeb91e2bd40e3a683ff434806386b8ee7bc\n",
      "  Building wheel for thriftpy2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for thriftpy2: filename=thriftpy2-0.5.2-cp311-cp311-linux_x86_64.whl size=841208 sha256=d0e87bda07ffb993e9c3ea4338e71ea0aa7b1e3e6fade449074d7dbe2bfe28ee\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/17/32/fa/51ae0364792430fb80858f4705c9e0cba3d6900f591f0c4495\n",
      "Successfully built finrl msgpack pyfolio elegantrl empyrical peewee thriftpy2\n",
      "Installing collected packages: webencodings, triton, sseclient-py, sortedcontainers, pytz, py-spy, ply, peewee, opencensus-context, nvidia-cusparselt-cu12, multitasking, msgpack, mpmath, korean_lunar_calendar, farama-notifications, distlib, colorful, wrapt, websockets, websocket-client, urllib3, tzdata, tqdm, toolz, threadpoolctl, tensorboard-data-server, tenacity, sympy, soupsieve, sniffio, rpds-py, PyYAML, python-dotenv, PySocks, pyparsing, pymysql, pyluach, pygame, pydantic-core, pycparser, pyasn1, pyarrow, psycopg2-binary, protobuf, propcache, prometheus-client, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, niltype, networkx, multidict, mdurl, MarkupSafe, markdown, lxml, kiwisolver, joblib, idna, html5lib, h11, grpcio, greenlet, fsspec, frozenlist, frozendict, fonttools, filelock, Cython, cycler, cloudpickle, click, charset-normalizer, certifi, cachetools, attrs, annotated-types, aiohappyeyeballs, absl-py, yarl, wsproto, werkzeug, virtualenv, thriftpy2, th, tensorboardX, SQLAlchemy, smart-open, scipy, rsa, requests, referencing, pydantic, pyasn1-modules, proto-plus, plotly, pandas, outcome, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, markdown-it-py, jinja2, gymnasium, googleapis-common-protos, deprecation, contourpy, cffi, beautifulsoup4, ale-py, aiosignal, yfinance, wrds, webdriver-manager, trio, tensorboard, stockstats, scs, scikit-learn, rich, qdldl, pycares, pandas-datareader, nvidia-cusolver-cu12, matplotlib, jsonschema-specifications, jqdatasdk, google-auth, exchange-calendars, ecos, cryptography, clarabel, alpaca-py, aiohttp, trio-websocket, torch, seaborn, osqp, jsonschema, google-api-core, empyrical, elegantrl, alpaca-trade-api, aiohttp-cors, aiodns, stable-baselines3, selenium, ray, pyfolio, opencensus, cvxpy, ccxt, pyportfolioopt, finrl\n",
      "Downloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: finrl, msgpack, pyfolio, elegantrl, empyrical, peewee, thriftpy2\n",
      "  Building wheel for finrl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for finrl: filename=finrl-0.3.6-py3-none-any.whl size=4695552 sha256=5a54289f77251e60544398dc46c96874f7c26a2a1588b6907ff2a5f9f4e450f1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jou107u0/wheels/22/04/d2/8ee1f0ed6a91622a6548d244772ae124a9b3795372817286a0\n",
      "  Building wheel for msgpack (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for msgpack: filename=msgpack-1.0.3-cp311-cp311-linux_x86_64.whl size=15741 sha256=3715cf18c5e8e31984f425f0d91ecb5e0d13cf044dce41c2d314b193e4dd9255\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/f6/35/da/ed9b26b510235e00e3a3c3bab7bad97b59214729662255ab3d\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88720 sha256=993c592e0b650f5f9e00bc4fa3434fc7a47f277ed734ac6aabfac8305913ef0b\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/f9/af/9e/7c343b822164a3147a3d395a1bcd05041c520a3bc6398fe88e\n",
      "  Building wheel for elegantrl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for elegantrl: filename=ElegantRL-0.3.10-py3-none-any.whl size=271988 sha256=8992bab4411eec05224a4d6778cafcf36a4b51082ba66752a3c4d8b94e115479\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jou107u0/wheels/9a/77/4d/6284111037b2dd64af9ef18d4d600d9c185cc2f6f09704e896\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39807 sha256=04ae75ee31963f0564083db2e48c132942893a62b24a7c2885a98d70148fc776\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/ac/1d/58/a7ae5ef5c8de7c4b769f24c2584f4706564921f031b16b9cb6\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.9-cp311-cp311-linux_x86_64.whl size=300871 sha256=2766ffb428c30f76106c5f9b4099a15b5d6ac28d02873a28da093e4599b189ff\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/f4/14/e4/50c88c865833085aeb91e2bd40e3a683ff434806386b8ee7bc\n",
      "  Building wheel for thriftpy2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for thriftpy2: filename=thriftpy2-0.5.2-cp311-cp311-linux_x86_64.whl size=841208 sha256=d0e87bda07ffb993e9c3ea4338e71ea0aa7b1e3e6fade449074d7dbe2bfe28ee\n",
      "  Stored in directory: /home/nyuad/.cache/pip/wheels/17/32/fa/51ae0364792430fb80858f4705c9e0cba3d6900f591f0c4495\n",
      "Successfully built finrl msgpack pyfolio elegantrl empyrical peewee thriftpy2\n",
      "Installing collected packages: webencodings, triton, sseclient-py, sortedcontainers, pytz, py-spy, ply, peewee, opencensus-context, nvidia-cusparselt-cu12, multitasking, msgpack, mpmath, korean_lunar_calendar, farama-notifications, distlib, colorful, wrapt, websockets, websocket-client, urllib3, tzdata, tqdm, toolz, threadpoolctl, tensorboard-data-server, tenacity, sympy, soupsieve, sniffio, rpds-py, PyYAML, python-dotenv, PySocks, pyparsing, pymysql, pyluach, pygame, pydantic-core, pycparser, pyasn1, pyarrow, psycopg2-binary, protobuf, propcache, prometheus-client, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, niltype, networkx, multidict, mdurl, MarkupSafe, markdown, lxml, kiwisolver, joblib, idna, html5lib, h11, grpcio, greenlet, fsspec, frozenlist, frozendict, fonttools, filelock, Cython, cycler, cloudpickle, click, charset-normalizer, certifi, cachetools, attrs, annotated-types, aiohappyeyeballs, absl-py, yarl, wsproto, werkzeug, virtualenv, thriftpy2, th, tensorboardX, SQLAlchemy, smart-open, scipy, rsa, requests, referencing, pydantic, pyasn1-modules, proto-plus, plotly, pandas, outcome, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, markdown-it-py, jinja2, gymnasium, googleapis-common-protos, deprecation, contourpy, cffi, beautifulsoup4, ale-py, aiosignal, yfinance, wrds, webdriver-manager, trio, tensorboard, stockstats, scs, scikit-learn, rich, qdldl, pycares, pandas-datareader, nvidia-cusolver-cu12, matplotlib, jsonschema-specifications, jqdatasdk, google-auth, exchange-calendars, ecos, cryptography, clarabel, alpaca-py, aiohttp, trio-websocket, torch, seaborn, osqp, jsonschema, google-api-core, empyrical, elegantrl, alpaca-trade-api, aiohttp-cors, aiodns, stable-baselines3, selenium, ray, pyfolio, opencensus, cvxpy, ccxt, pyportfolioopt, finrl\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "Successfully installed Cython-3.0.11 MarkupSafe-3.0.2 PySocks-1.7.1 PyYAML-6.0.1 SQLAlchemy-2.0.37 absl-py-2.1.0 aiodns-3.2.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.12 aiohttp-cors-0.7.0 aiosignal-1.3.2 ale-py-0.10.1 alpaca-py-0.37.0 alpaca-trade-api-3.2.0 annotated-types-0.7.0 attrs-25.1.0 beautifulsoup4-4.13.3 cachetools-5.5.1 ccxt-3.1.60 certifi-2025.1.31 cffi-1.17.1 charset-normalizer-3.4.1 clarabel-0.10.0 click-8.1.8 cloudpickle-3.1.1 colorful-0.5.6 contourpy-1.3.1 cryptography-44.0.0 cvxpy-1.6.0 cycler-0.12.1 deprecation-2.1.0 distlib-0.3.9 ecos-2.0.14 elegantrl-0.3.10 empyrical-0.5.5 exchange-calendars-4.9 farama-notifications-0.0.4 filelock-3.17.0 finrl-0.3.6 fonttools-4.55.8 frozendict-2.4.6 frozenlist-1.5.0 fsspec-2025.2.0 google-api-core-2.24.1 google-auth-2.38.0 googleapis-common-protos-1.66.0 greenlet-3.1.1 grpcio-1.70.0 gymnasium-1.0.0 h11-0.14.0 html5lib-1.1 idna-3.10 jinja2-3.1.5 joblib-1.4.2 jqdatasdk-1.9.7 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 kiwisolver-1.4.8 korean_lunar_calendar-0.3.1 lxml-5.3.0 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.0 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.0.3 multidict-6.1.0 multitasking-0.0.11 networkx-3.4.2 niltype-1.0.2 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opencv-python-4.11.0.86 osqp-0.6.7.post3 outcome-1.3.0.post0 packaging-23.2 pandas-2.2.3 pandas-datareader-0.10.0 peewee-3.17.9 pillow-11.1.0 plotly-5.24.1 ply-3.11 prometheus-client-0.21.1 propcache-0.2.1 proto-plus-1.26.0 protobuf-5.29.3 psycopg2-binary-2.9.10 py-spy-0.4.0 pyarrow-19.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycares-4.5.0 pycparser-2.22 pydantic-2.10.6 pydantic-core-2.27.2 pyfolio-0.9.2 pygame-2.6.1 pyluach-2.2.0 pymysql-1.1.1 pyparsing-3.2.1 pyportfolioopt-1.5.6 python-dotenv-1.0.1 pytz-2025.1 qdldl-0.1.7.post5 ray-2.42.0 referencing-0.36.2 requests-2.32.3 rich-13.9.4 rpds-py-0.22.3 rsa-4.9 scikit-learn-1.6.1 scipy-1.12.0 scs-3.2.7.post2 seaborn-0.13.2 selenium-4.28.1 smart-open-7.1.0 sniffio-1.3.1 sortedcontainers-2.4.0 soupsieve-2.6 sseclient-py-1.8.0 stable-baselines3-2.6.0a0 stockstats-0.5.4 sympy-1.13.1 tenacity-9.0.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 th-0.4.1 threadpoolctl-3.5.0 thriftpy2-0.5.2 toolz-1.0.0 torch-2.6.0 tqdm-4.67.1 trio-0.28.0 trio-websocket-0.11.1 triton-3.2.0 tzdata-2025.1 urllib3-1.26.20 virtualenv-20.29.1 webdriver-manager-4.0.2 webencodings-0.5.1 websocket-client-1.8.0 websockets-10.4 werkzeug-3.1.3 wrapt-1.17.2 wrds-3.2.0 wsproto-1.2.0 yarl-1.18.3 yfinance-0.2.52\n"
      "Successfully installed Cython-3.0.11 MarkupSafe-3.0.2 PySocks-1.7.1 PyYAML-6.0.1 SQLAlchemy-2.0.37 absl-py-2.1.0 aiodns-3.2.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.12 aiohttp-cors-0.7.0 aiosignal-1.3.2 ale-py-0.10.1 alpaca-py-0.37.0 alpaca-trade-api-3.2.0 annotated-types-0.7.0 attrs-25.1.0 beautifulsoup4-4.13.3 cachetools-5.5.1 ccxt-3.1.60 certifi-2025.1.31 cffi-1.17.1 charset-normalizer-3.4.1 clarabel-0.10.0 click-8.1.8 cloudpickle-3.1.1 colorful-0.5.6 contourpy-1.3.1 cryptography-44.0.0 cvxpy-1.6.0 cycler-0.12.1 deprecation-2.1.0 distlib-0.3.9 ecos-2.0.14 elegantrl-0.3.10 empyrical-0.5.5 exchange-calendars-4.9 farama-notifications-0.0.4 filelock-3.17.0 finrl-0.3.6 fonttools-4.55.8 frozendict-2.4.6 frozenlist-1.5.0 fsspec-2025.2.0 google-api-core-2.24.1 google-auth-2.38.0 googleapis-common-protos-1.66.0 greenlet-3.1.1 grpcio-1.70.0 gymnasium-1.0.0 h11-0.14.0 html5lib-1.1 idna-3.10 jinja2-3.1.5 joblib-1.4.2 jqdatasdk-1.9.7 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 kiwisolver-1.4.8 korean_lunar_calendar-0.3.1 lxml-5.3.0 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.0 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.0.3 multidict-6.1.0 multitasking-0.0.11 networkx-3.4.2 niltype-1.0.2 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opencv-python-4.11.0.86 osqp-0.6.7.post3 outcome-1.3.0.post0 packaging-23.2 pandas-2.2.3 pandas-datareader-0.10.0 peewee-3.17.9 pillow-11.1.0 plotly-5.24.1 ply-3.11 prometheus-client-0.21.1 propcache-0.2.1 proto-plus-1.26.0 protobuf-5.29.3 psycopg2-binary-2.9.10 py-spy-0.4.0 pyarrow-19.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycares-4.5.0 pycparser-2.22 pydantic-2.10.6 pydantic-core-2.27.2 pyfolio-0.9.2 pygame-2.6.1 pyluach-2.2.0 pymysql-1.1.1 pyparsing-3.2.1 pyportfolioopt-1.5.6 python-dotenv-1.0.1 pytz-2025.1 qdldl-0.1.7.post5 ray-2.42.0 referencing-0.36.2 requests-2.32.3 rich-13.9.4 rpds-py-0.22.3 rsa-4.9 scikit-learn-1.6.1 scipy-1.12.0 scs-3.2.7.post2 seaborn-0.13.2 selenium-4.28.1 smart-open-7.1.0 sniffio-1.3.1 sortedcontainers-2.4.0 soupsieve-2.6 sseclient-py-1.8.0 stable-baselines3-2.6.0a0 stockstats-0.5.4 sympy-1.13.1 tenacity-9.0.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 th-0.4.1 threadpoolctl-3.5.0 thriftpy2-0.5.2 toolz-1.0.0 torch-2.6.0 tqdm-4.67.1 trio-0.28.0 trio-websocket-0.11.1 triton-3.2.0 tzdata-2025.1 urllib3-1.26.20 virtualenv-20.29.1 webdriver-manager-4.0.2 webencodings-0.5.1 websocket-client-1.8.0 websockets-10.4 werkzeug-3.1.3 wrapt-1.17.2 wrds-3.2.0 wsproto-1.2.0 yarl-1.18.3 yfinance-0.2.52\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (1.26.4)\n"
      "Requirement already satisfied: pandas in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !set PATH=%PATH%;C:\\Users\\natna\\miniforge3\\envs\\finRl\\Scripts\n"
    "# !set PATH=%PATH%;C:\\Users\\natna\\miniforge3\\envs\\finRl\\Scripts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy==1.12.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from scikit-learn==1.6.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from scikit-learn==1.6.1) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
      "Requirement already satisfied: numpy==1.26.4 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy==1.12.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from scikit-learn==1.6.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from scikit-learn==1.6.1) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4 scipy==1.12.0 scikit-learn==1.6.1 pandas\n",
    "!pip install numpy==1.26.4 scipy==1.12.0 scikit-learn==1.6.1 pandas\n",
    "\n",
    "\n",
    "\n",
    "# !python --version 1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "  File \"/tmp/ipykernel_9305/730609322.py\", line 1, in <module>\n",
      "    import numpy\n",
      "ModuleNotFoundError: No module named 'numpy'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1136, in get_records\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "  File \"/tmp/ipykernel_9305/730609322.py\", line 1, in <module>\n",
      "    import numpy\n",
      "ModuleNotFoundError: No module named 'numpy'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1136, in get_records\n",
      "  File \"/home/nyuad/miniconda3/envs/finRl/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "# import numpy\n",
    "# import scipy\n",
    "# import sklearn\n",
    "# print(\"Numpy version:\", numpy.__version__)\n",
    "# print(\"Scipy version:\", scipy.__version__)\n",
    "# print(\"Scikit-learn version:\", sklearn.__version__)\n"
    "# import numpy\n",
    "# import scipy\n",
    "# import sklearn\n",
    "# print(\"Numpy version:\", numpy.__version__)\n",
    "# print(\"Scipy version:\", scipy.__version__)\n",
    "# print(\"Scikit-learn version:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JumKAPcK1t3"
   },
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "error",
     "timestamp": 1738147118819,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "QplTAkT7I2_n",
    "outputId": "2f02a388-e14d-4826-a3b5-33624c41fbc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl import config\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SkZZUKZK46-"
   },
   "source": [
    "Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_count": 4,
   "metadata": {
    "id": "uEIa8z8rI3YZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIWTB6spLAZC"
   },
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12389,
     "status": "ok",
     "timestamp": 1730810015401,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "nx66rCNoUwpf",
    "outputId": "c1bc9ad2-8788-43f7-b065-358792fef2b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (86111, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from finrl import config_tickers\n",
    "df = YahooDownloader(start_date = '2009-01-01',\n",
    "                           end_date = '2020-09-30',\n",
    "                           ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_indicators = config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43845,
     "status": "ok",
     "timestamp": 1730810059241,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "9HRIUe4BVVgj",
    "outputId": "44e8b82f-5daf-4888-b971-c563d7679cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "df = FeatureEngineer(use_technical_indicator=True,\n",
    "                      tech_indicator_list = tech_indicators,\n",
    "                      use_turbulence=True,\n",
    "                      user_defined_feature = False).preprocess_data(df.copy()).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 34076,
     "status": "ok",
     "timestamp": 1730810093313,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "CtDEpQ-KVfjv",
    "outputId": "9fdb3922-dacc-4bb4-d1d9-2b546f814d5f"
   },
   "outputs": [],
   "source": [
    "df=df.sort_values(['date','tic'],ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "df = df.reset_index(drop=True)\n",
    "# cov_list = []\n",
    "# # look back is one year\n",
    "# lookback=252\n",
    "# for i in range(lookback,len(df.index.unique())):\n",
    "#   data_lookback = df.loc[i-lookback:i,:]\n",
    "#   price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "#   return_lookback = price_lookback.pct_change().dropna()\n",
    "#   covs = return_lookback.cov().values\n",
    "#   cov_list.append(covs)\n",
    "\n",
    "# df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list})\n",
    "# df = df.merge(df_cov, on='date')\n",
    "# df = df.sort_values(['date','tic']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39829</th>\n",
       "      <td>2014-06-18</td>\n",
       "      <td>112.596130</td>\n",
       "      <td>175.535370</td>\n",
       "      <td>173.795410</td>\n",
       "      <td>174.034424</td>\n",
       "      <td>4112663</td>\n",
       "      <td>IBM</td>\n",
       "      <th>39829</th>\n",
       "      <td>2014-06-18</td>\n",
       "      <td>112.596130</td>\n",
       "      <td>175.535370</td>\n",
       "      <td>173.795410</td>\n",
       "      <td>174.034424</td>\n",
       "      <td>4112663</td>\n",
       "      <td>IBM</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.904203</td>\n",
       "      <td>114.982996</td>\n",
       "      <td>111.046917</td>\n",
       "      <td>46.307122</td>\n",
       "      <td>-88.077769</td>\n",
       "      <td>20.276630</td>\n",
       "      <td>113.921570</td>\n",
       "      <td>115.864071</td>\n",
       "      <td>23.503516</td>\n",
       "      <td>-0.904203</td>\n",
       "      <td>114.982996</td>\n",
       "      <td>111.046917</td>\n",
       "      <td>46.307122</td>\n",
       "      <td>-88.077769</td>\n",
       "      <td>20.276630</td>\n",
       "      <td>113.921570</td>\n",
       "      <td>115.864071</td>\n",
       "      <td>23.503516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47149</th>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>104.622307</td>\n",
       "      <td>121.379997</td>\n",
       "      <td>119.919998</td>\n",
       "      <td>120.389999</td>\n",
       "      <td>3478300</td>\n",
       "      <td>UNH</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651252</td>\n",
       "      <td>105.260609</td>\n",
       "      <td>99.872495</td>\n",
       "      <td>56.079358</td>\n",
       "      <td>106.064634</td>\n",
       "      <td>25.319770</td>\n",
       "      <td>102.135494</td>\n",
       "      <td>101.606909</td>\n",
       "      <td>11.587459</td>\n",
       "      <th>47149</th>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>104.622307</td>\n",
       "      <td>121.379997</td>\n",
       "      <td>119.919998</td>\n",
       "      <td>120.389999</td>\n",
       "      <td>3478300</td>\n",
       "      <td>UNH</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651252</td>\n",
       "      <td>105.260609</td>\n",
       "      <td>99.872495</td>\n",
       "      <td>56.079358</td>\n",
       "      <td>106.064634</td>\n",
       "      <td>25.319770</td>\n",
       "      <td>102.135494</td>\n",
       "      <td>101.606909</td>\n",
       "      <td>11.587459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58613</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>77.479980</td>\n",
       "      <td>94.370003</td>\n",
       "      <td>92.779999</td>\n",
       "      <td>94.370003</td>\n",
       "      <td>3102700</td>\n",
       "      <td>CAT</td>\n",
       "      <th>58613</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>77.479980</td>\n",
       "      <td>94.370003</td>\n",
       "      <td>92.779999</td>\n",
       "      <td>94.370003</td>\n",
       "      <td>3102700</td>\n",
       "      <td>CAT</td>\n",
       "      <td>3</td>\n",
       "      <td>0.113317</td>\n",
       "      <td>78.349124</td>\n",
       "      <td>75.995053</td>\n",
       "      <td>54.669809</td>\n",
       "      <td>-45.996271</td>\n",
       "      <td>6.374223</td>\n",
       "      <td>77.740197</td>\n",
       "      <td>75.404240</td>\n",
       "      <td>13.478764</td>\n",
       "      <td>0.113317</td>\n",
       "      <td>78.349124</td>\n",
       "      <td>75.995053</td>\n",
       "      <td>54.669809</td>\n",
       "      <td>-45.996271</td>\n",
       "      <td>6.374223</td>\n",
       "      <td>77.740197</td>\n",
       "      <td>75.404240</td>\n",
       "      <td>13.478764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66813</th>\n",
       "      <td>2018-02-27</td>\n",
       "      <td>33.186626</td>\n",
       "      <td>49.169998</td>\n",
       "      <td>48.040001</td>\n",
       "      <td>49.020000</td>\n",
       "      <td>23234700</td>\n",
       "      <td>VZ</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.707983</td>\n",
       "      <td>37.554438</td>\n",
       "      <td>31.959930</td>\n",
       "      <td>42.374442</td>\n",
       "      <td>-99.088989</td>\n",
       "      <td>32.290347</td>\n",
       "      <td>35.396301</td>\n",
       "      <td>35.580750</td>\n",
       "      <td>54.676032</td>\n",
       "      <th>66813</th>\n",
       "      <td>2018-02-27</td>\n",
       "      <td>33.186626</td>\n",
       "      <td>49.169998</td>\n",
       "      <td>48.040001</td>\n",
       "      <td>49.020000</td>\n",
       "      <td>23234700</td>\n",
       "      <td>VZ</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.707983</td>\n",
       "      <td>37.554438</td>\n",
       "      <td>31.959930</td>\n",
       "      <td>42.374442</td>\n",
       "      <td>-99.088989</td>\n",
       "      <td>32.290347</td>\n",
       "      <td>35.396301</td>\n",
       "      <td>35.580750</td>\n",
       "      <td>54.676032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33399</th>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>26.226957</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>43898400</td>\n",
       "      <td>MSFT</td>\n",
       "      <th>33399</th>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>26.226957</td>\n",
       "      <td>32.049999</td>\n",
       "      <td>31.709999</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>43898400</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.632170</td>\n",
       "      <td>30.738967</td>\n",
       "      <td>24.615243</td>\n",
       "      <td>44.190587</td>\n",
       "      <td>-99.856841</td>\n",
       "      <td>33.851980</td>\n",
       "      <td>27.801897</td>\n",
       "      <td>28.083239</td>\n",
       "      <td>90.741376</td>\n",
       "      <td>-0.632170</td>\n",
       "      <td>30.738967</td>\n",
       "      <td>24.615243</td>\n",
       "      <td>44.190587</td>\n",
       "      <td>-99.856841</td>\n",
       "      <td>33.851980</td>\n",
       "      <td>27.801897</td>\n",
       "      <td>28.083239</td>\n",
       "      <td>90.741376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date       close        high         low        open    volume  \\\n",
       "39829  2014-06-18  112.596130  175.535370  173.795410  174.034424   4112663   \n",
       "47149  2015-06-18  104.622307  121.379997  119.919998  120.389999   3478300   \n",
       "58613  2017-01-12   77.479980   94.370003   92.779999   94.370003   3102700   \n",
       "66813  2018-02-27   33.186626   49.169998   48.040001   49.020000  23234700   \n",
       "33399  2013-07-31   26.226957   32.049999   31.709999   31.969999  43898400   \n",
       "39829  2014-06-18  112.596130  175.535370  173.795410  174.034424   4112663   \n",
       "47149  2015-06-18  104.622307  121.379997  119.919998  120.389999   3478300   \n",
       "58613  2017-01-12   77.479980   94.370003   92.779999   94.370003   3102700   \n",
       "66813  2018-02-27   33.186626   49.169998   48.040001   49.020000  23234700   \n",
       "33399  2013-07-31   26.226957   32.049999   31.709999   31.969999  43898400   \n",
       "\n",
       "        tic  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
       "39829   IBM    2 -0.904203  114.982996  111.046917  46.307122  -88.077769   \n",
       "47149   UNH    3  0.651252  105.260609   99.872495  56.079358  106.064634   \n",
       "58613   CAT    3  0.113317   78.349124   75.995053  54.669809  -45.996271   \n",
       "66813    VZ    1 -0.707983   37.554438   31.959930  42.374442  -99.088989   \n",
       "33399  MSFT    2 -0.632170   30.738967   24.615243  44.190587  -99.856841   \n",
       "        tic  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
       "39829   IBM    2 -0.904203  114.982996  111.046917  46.307122  -88.077769   \n",
       "47149   UNH    3  0.651252  105.260609   99.872495  56.079358  106.064634   \n",
       "58613   CAT    3  0.113317   78.349124   75.995053  54.669809  -45.996271   \n",
       "66813    VZ    1 -0.707983   37.554438   31.959930  42.374442  -99.088989   \n",
       "33399  MSFT    2 -0.632170   30.738967   24.615243  44.190587  -99.856841   \n",
       "\n",
       "           dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "39829  20.276630    113.921570    115.864071   23.503516  \n",
       "47149  25.319770    102.135494    101.606909   11.587459  \n",
       "58613   6.374223     77.740197     75.404240   13.478764  \n",
       "66813  32.290347     35.396301     35.580750   54.676032  \n",
       "33399  33.851980     27.801897     28.083239   90.741376  "
       "39829  20.276630    113.921570    115.864071   23.503516  \n",
       "47149  25.319770    102.135494    101.606909   11.587459  \n",
       "58613   6.374223     77.740197     75.404240   13.478764  \n",
       "66813  32.290347     35.396301     35.580750   54.676032  \n",
       "33399  33.851980     27.801897     28.083239   90.741376  "
      ]
     },
     "execution_count": 9,
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QupbraDPX2CX"
   },
   "source": [
    "In real life trading, the model needs to be updated periodically using rolling windows. But here I'm just cutting the data into train and trade set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1730810093313,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "QXvQ-kfbXEMJ",
    "outputId": "dec64cc9-6b48-46e6-c337-a17022efd459"
   },
   "outputs": [],
   "source": [
    "train = data_split(df, '2009-01-01','2019-12-31')\n",
    "trade = data_split(df, '2020-01-01','2020-09-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqbKpVIvW4dy"
   },
   "source": [
    "State Space and Action Space Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1730810093314,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "2ukHtLtfWfF4",
    "outputId": "1a646bce-dd56-4b72-f39d-c638c285c5ed"
   },
   "outputs": [],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "print(stock_dimension)\n",
    "print(state_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "execution_count": 13,
   "metadata": {
    "id": "hcFRuEVUW5Mb"
   },
   "outputs": [],
   "source": [
    "# Define transaction cost lists for buying and selling stocks\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "# Explanation: \n",
    "# - `buy_cost_list` and `sell_cost_list` represent the transaction costs as a percentage for buying and selling stocks.\n",
    "# - `[0.001] * stock_dimension` creates a list where each element is 0.001 (0.1% transaction fee), repeated for each stock.\n",
    "# - The use of `=` assigns the same list to both `buy_cost_list` and `sell_cost_list`.\n",
    "\n",
    "# Initialize the list to track the number of shares owned for each stock\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "# Explanation:\n",
    "# - `num_stock_shares` is a list where each element is initialized to 0, representing that no shares are owned initially.\n",
    "# - `[0] * stock_dimension` ensures the list length matches the number of stocks (`stock_dimension`).\n",
    "\n",
    "# Create a dictionary to store environment configuration parameters\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,  # Maximum number of shares that can be bought or sold in a single transaction.\n",
    "    \"initial_amount\": 1_000_000,  # Initial cash available for the agent to trade with (e.g., $1,000,000).\n",
    "    \"num_stock_shares\": num_stock_shares,  # Initial portfolio: number of shares owned for each stock.\n",
    "    \"buy_cost_pct\": buy_cost_list,  # Transaction cost percentage for buying stocks.\n",
    "    \"sell_cost_pct\": sell_cost_list,  # Transaction cost percentage for selling stocks.\n",
    "    \"state_space\": state_space,  # Dimension of the state space (e.g., features describing the environment).\n",
    "    \"stock_dim\": stock_dimension,  # Number of stocks being traded (dimension of the stock universe).\n",
    "    \"tech_indicator_list\": config.INDICATORS,  # List of technical indicators used as features for the state space.\n",
    "    \"action_space\": stock_dimension,  # Dimension of the action space (one action per stock).\n",
    "    \"reward_scaling\": 1e-4,  # Scaling factor for rewards to normalize them and improve learning stability.\n",
    "    \"print_verbosity\":5\n",
    "}\n",
    "# Explanation:\n",
    "# - This dictionary (`env_kwargs`) encapsulates all the necessary parameters required to initialize the stock trading environment.\n",
    "# - It includes configuration for portfolio management (e.g., `hmax`, `initial_amount`, `num_stock_shares`) and the structure of the RL problem (e.g., `state_space`, `action_space`).\n",
    "\n",
    "# Initialize the stock trading environment with the training data and configuration parameters\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)\n",
    "# Explanation:\n",
    "# - `StockTradingEnv` is a custom environment class for stock trading, compliant with OpenAI Gym standards.\n",
    "# - `df=train` specifies the training data (a DataFrame containing historical stock prices and other features).\n",
    "# - `**env_kwargs` unpacks the `env_kwargs` dictionary, passing each key-value pair as an argument to the environment initializer.\n",
    "# - The environment simulates the stock trading process, enabling the RL agent to interact with it by observing states, taking actions, and receiving rewards.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OMN6ZYNd_fC"
   },
   "source": [
    "Environment for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730810093314,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "Cj33JvyIX-pm",
    "outputId": "e21de6e2-91d0-4d35-a662-0d362b53f3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env() #get stable baseline environment for training\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "execution_count": 15,
   "metadata": {
    "id": "c29I-eqQeE-9"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "# Set the corresponding values to 'True' for the algorithms that you want to use\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "execution_count": 16,
   "metadata": {
    "id": "OKPImGqQe0yl"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.logger import configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuSrLRD8eEma"
   },
   "source": [
    " Implement DRL Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current version of PyTorch:  2.6.0+cu124\n",
      "Current version of PyTorch:  2.6.0+cu124\n",
      "PyTorch can use GPUs!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print('Current version of PyTorch: ', torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available:\n",
    "  print('PyTorch can use GPUs!')\n",
    "else:\n",
    "  print('PyTorch cannot use GPUs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ir3Qf4BedYD"
   },
   "source": [
    "DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QslI7kC_iWGz"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4503,
     "status": "ok",
     "timestamp": 1730810097812,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "qCWbsuVKeGsT",
    "outputId": "19397fc6-5736-477d-9407-4eca82b68275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = config.RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 827716,
     "status": "ok",
     "timestamp": 1730810925525,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "OLv-G6f5egU9",
    "outputId": "60b02534-683f-4fe2-d33e-df8215d9db5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2766, episode: 5\n",
      "day: 2766, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6696059.57\n",
      "total_reward: 5696059.57\n",
      "total_cost: 999.00\n",
      "total_trades: 38724\n",
      "Sharpe: 1.134\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 136        |\n",
      "|    time_elapsed    | 81         |\n",
      "|    total_timesteps | 11068      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -20.8      |\n",
      "|    critic_loss     | 10         |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 10967      |\n",
      "|    reward          | -5.7804456 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 135        |\n",
      "|    time_elapsed    | 162        |\n",
      "|    total_timesteps | 22136      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -20.5      |\n",
      "|    critic_loss     | 3.51       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 22035      |\n",
      "|    reward          | -5.7804456 |\n",
      "-----------------------------------\n",
      "day: 2766, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6696059.57\n",
      "total_reward: 5696059.57\n",
      "total_cost: 999.00\n",
      "total_trades: 38724\n",
      "Sharpe: 1.134\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 134        |\n",
      "|    time_elapsed    | 246        |\n",
      "|    total_timesteps | 33204      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -19.8      |\n",
      "|    critic_loss     | 5.08       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 33103      |\n",
      "|    reward          | -5.7804456 |\n",
      "-----------------------------------\n",
      "day: 2766, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6696059.57\n",
      "total_reward: 5696059.57\n",
      "total_cost: 999.00\n",
      "total_trades: 38724\n",
      "Sharpe: 1.134\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 135        |\n",
      "|    time_elapsed    | 325        |\n",
      "|    total_timesteps | 44272      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -19        |\n",
      "|    critic_loss     | 3.25       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 44171      |\n",
      "|    reward          | -5.7804456 |\n",
      "-----------------------------------\n"
      "end_total_asset: 6696059.57\n",
      "total_reward: 5696059.57\n",
      "total_cost: 999.00\n",
      "total_trades: 38724\n",
      "Sharpe: 1.134\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 136        |\n",
      "|    time_elapsed    | 81         |\n",
      "|    total_timesteps | 11068      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -20.8      |\n",
      "|    critic_loss     | 10         |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 10967      |\n",
      "|    reward          | -5.7804456 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 135        |\n",
      "|    time_elapsed    | 162        |\n",
      "|    total_timesteps | 22136      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -20.5      |\n",
      "|    critic_loss     | 3.51       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 22035      |\n",
      "|    reward          | -5.7804456 |\n",
      "-----------------------------------\n",
      "day: 2766, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6696059.57\n",
      "total_reward: 5696059.57\n",
      "total_cost: 999.00\n",
      "total_trades: 38724\n",
      "Sharpe: 1.134\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 134        |\n",
      "|    time_elapsed    | 246        |\n",
      "|    total_timesteps | 33204      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -19.8      |\n",
      "|    critic_loss     | 5.08       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 33103      |\n",
      "|    reward          | -5.7804456 |\n",
      "-----------------------------------\n",
      "day: 2766, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6696059.57\n",
      "total_reward: 5696059.57\n",
      "total_cost: 999.00\n",
      "total_trades: 38724\n",
      "Sharpe: 1.134\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 135        |\n",
      "|    time_elapsed    | 325        |\n",
      "|    total_timesteps | 44272      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -19        |\n",
      "|    critic_loss     | 3.25       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 44171      |\n",
      "|    reward          | -5.7804456 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg,\n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1730810925526,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "gkfZxJDne9Ga",
    "outputId": "f1179c7a-a44a-4224-bf7a-6cbfb21548e7"
   },
   "outputs": [],
   "source": [
    "trained_ddpg.save(config.TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYEHIiGBiYkF"
   },
   "source": [
    "Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "execution_count": 21,
   "metadata": {
    "id": "sXDO2YkqiBTY"
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1730810925996,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "sw_llsYlifvO",
    "outputId": "287fd348-832d-4fa8-9a28-fbfeb9bd40cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BA</th>\n",
       "      <th>CAT</th>\n",
       "      <th>CRM</th>\n",
       "      <th>CSCO</th>\n",
       "      <th>CVX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>GS</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>V</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WMT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL  AMGN  AXP   BA  CAT  CRM  CSCO  CVX  DIS  GS  ...  MRK  \\\n",
       "date                                                            ...        \n",
       "2020-01-02     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "2020-01-03     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "2020-01-06     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "2020-01-07     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "2020-01-08     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "            AAPL  AMGN  AXP   BA  CAT  CRM  CSCO  CVX  DIS  GS  ...  MRK  \\\n",
       "date                                                            ...        \n",
       "2020-01-02     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "2020-01-03     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "2020-01-06     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "2020-01-07     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "2020-01-08     0     0    0  100  100  100     0    0    0   0  ...    0   \n",
       "\n",
       "            MSFT  NKE  PG  TRV  UNH    V   VZ  WBA  WMT  \n",
       "date                                                     \n",
       "2020-01-02   100    0   0  100    0  100  100  100  100  \n",
       "2020-01-03   100    0   0  100    0  100  100  100  100  \n",
       "2020-01-06   100    0   0  100    0  100  100  100  100  \n",
       "2020-01-07   100    0   0  100    0  100  100  100  100  \n",
       "2020-01-08   100    0   0  100    0  100  100  100  100  \n",
       "            MSFT  NKE  PG  TRV  UNH    V   VZ  WBA  WMT  \n",
       "date                                                     \n",
       "2020-01-02   100    0   0  100    0  100  100  100  100  \n",
       "2020-01-03   100    0   0  100    0  100  100  100  100  \n",
       "2020-01-06   100    0   0  100    0  100  100  100  100  \n",
       "2020-01-07   100    0   0  100    0  100  100  100  100  \n",
       "2020-01-08   100    0   0  100    0  100  100  100  100  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1730810925996,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "LA6LdD6piy3t",
    "outputId": "27bf8a54-a0fe-4dbf-d323-a8dcfb19b361"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>944842.943405</td>\n",
       "      <td>944842.943405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>944964.964004</td>\n",
       "      <td>944964.964004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>961721.568924</td>\n",
       "      <td>961721.568924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>980190.710014</td>\n",
       "      <td>980190.710014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>974907.469173</td>\n",
       "      <td>974907.469173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "183  2020-09-23  944842.943405\n",
       "184  2020-09-24  944964.964004\n",
       "185  2020-09-25  961721.568924\n",
       "186  2020-09-28  980190.710014\n",
       "187  2020-09-29  974907.469173"
       "183  2020-09-23  944842.943405\n",
       "184  2020-09-24  944964.964004\n",
       "185  2020-09-25  961721.568924\n",
       "186  2020-09-28  980190.710014\n",
       "187  2020-09-29  974907.469173"
      ]
     },
     "execution_count": 24,
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWjKPG7gjgZ_"
   },
   "source": [
    "Backtesting Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1730810926475,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "63_gK7T2pkpm",
    "outputId": "0ecc1608-4b1e-4367-9a74-bbb923f33e2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (183, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_dji = YahooDownloader(\n",
    "    start_date='2020-01-01', end_date='2020-09-30', ticker_list=[\"dji\"]\n",
    ").fetch_data()\n",
    "df_dji = df_dji[[\"date\", \"close\"]]\n",
    "fst_day = df_dji[\"close\"][0]\n",
    "dji = pd.merge(\n",
    "    df_dji[\"date\"],\n",
    "    df_dji[\"close\"].div(fst_day).mul(1000000),\n",
    "    how=\"outer\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ").set_index(\"date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1730810926475,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "-h4JjB_ejfzz",
    "outputId": "64f57769-7f27-4e36-b971-83ef4a61a2a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return         -0.050662\n",
      "Cumulative returns    -0.038044\n",
      "Annual volatility      0.399601\n",
      "Sharpe ratio           0.069960\n",
      "Calmar ratio          -0.141434\n",
      "Stability              0.000611\n",
      "Max drawdown          -0.358206\n",
      "Omega ratio            1.014689\n",
      "Sortino ratio          0.095153\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.858610\n",
      "Daily value at risk   -0.050234\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1730810926475,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "Tb3VVI48k78N",
    "outputId": "5456ca04-b0ae-42d1-b63f-ae47e2b88498"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "Shape of DataFrame:  (188, 8)\n",
      "Annual return         -0.065199\n",
      "Cumulative returns    -0.049054\n",
      "Annual volatility      0.416030\n",
      "Sharpe ratio           0.046016\n",
      "Calmar ratio          -0.175803\n",
      "Stability              0.012240\n",
      "Max drawdown          -0.370862\n",
      "Omega ratio            1.009343\n",
      "Sortino ratio          0.062829\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.860019\n",
      "Daily value at risk   -0.052339\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\",\n",
    "        start = '2020-01-01',\n",
    "        end = '2020-09-30')\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NIMIMEvk_N0"
   },
   "source": [
    "Back Test Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1730810926475,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "78hETy-VlHqK",
    "outputId": "ff6b429f-b62f-4fc3-f4a6-eca464b79ec9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ddpg</th>\n",
       "      <th>dji</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>9.978712e+05</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>9.981349e+05</td>\n",
       "      <td>1.002392e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>9.939272e+05</td>\n",
       "      <td>9.982119e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>1.000095e+06</td>\n",
       "      <td>1.003848e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-23</th>\n",
       "      <td>9.234568e+05</td>\n",
       "      <td>9.346322e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-24</th>\n",
       "      <td>9.281680e+05</td>\n",
       "      <td>9.364587e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>9.375273e+05</td>\n",
       "      <td>9.489818e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>9.505631e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>9.448979e+05</td>\n",
       "      <td>9.587147e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ddpg           dji\n",
       "date                                  \n",
       "2020-01-02  1.000000e+06           NaN\n",
       "2020-01-03  9.978712e+05  1.000000e+06\n",
       "2020-01-06  9.981349e+05  1.002392e+06\n",
       "2020-01-07  9.939272e+05  9.982119e+05\n",
       "2020-01-08  1.000095e+06  1.003848e+06\n",
       "...                  ...           ...\n",
       "2020-09-23  9.234568e+05  9.346322e+05\n",
       "2020-09-24  9.281680e+05  9.364587e+05\n",
       "2020-09-25  9.375273e+05  9.489818e+05\n",
       "2020-09-28  9.505631e+05           NaN\n",
       "2020-09-29  9.448979e+05  9.587147e+05\n",
       "\n",
       "[188 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_ddpg = df_account_value.set_index(df_account_value.columns[0])\n",
    "result = pd.DataFrame(\n",
    "    {\n",
    "        \"ddpg\": df_result_ddpg[\"account_value\"],\n",
    "        \"dji\": dji[\"close\"],\n",
    "    }\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1730810927018,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "3WrmcZJzpTRb",
    "outputId": "7dca1921-a179-4da1-a3bb-d256ecdf545e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sHor4GwffzI"
   },
   "source": [
    "PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1730810927018,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "mAAyC44Ue-Uq",
    "outputId": "97fdd59a-8c4e-4e4c-9c71-de950bc9f392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to results/ppo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "/home/nyuad/miniconda3/envs/finRl/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = config.RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2132596,
     "status": "ok",
     "timestamp": 1730813059609,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "1kFtG_wYfoHB",
    "outputId": "a4bbbf7a-5c11-4bc9-b30d-155f852a122e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 225         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 9           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.30444476 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 225         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 9           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.30444476 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016307686 |\n",
      "|    approx_kl            | 0.016307686 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0223     |\n",
      "|    explained_variance   | -0.0223     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.28        |\n",
      "|    loss                 | 4.28        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | 0.88291067  |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | 0.88291067  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 10.9        |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01539087  |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    approx_kl            | 0.01539087  |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.0207      |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.0207      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.45        |\n",
      "|    loss                 | 7.45        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    reward               | -0.73351717 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    reward               | -0.73351717 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011945495 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    approx_kl            | 0.011945495 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00456    |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00456    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | 0.15318808  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 34.7        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | 0.15318808  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 10240       |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013986781 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    approx_kl            | 0.013986781 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00573    |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00573    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.94        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 1.9968919   |\n",
      "|    loss                 | 8.94        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 1.9968919   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 21.1        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01824338 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.0164     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.08       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0199    |\n",
      "|    reward               | 0.07695262 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 13.6       |\n",
      "----------------------------------------\n",
      "day: 2766, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4502345.30\n",
      "total_reward: 3502345.30\n",
      "total_cost: 292793.46\n",
      "total_trades: 76410\n",
      "Sharpe: 1.015\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01915547 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0309    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.3        |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    reward               | -0.2168774 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 18.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01824338 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.4      |\n",
      "|    explained_variance   | 0.0164     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.08       |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0199    |\n",
      "|    reward               | 0.07695262 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 13.6       |\n",
      "----------------------------------------\n",
      "day: 2766, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4502345.30\n",
      "total_reward: 3502345.30\n",
      "total_cost: 292793.46\n",
      "total_trades: 76410\n",
      "Sharpe: 1.015\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01915547 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | -0.0309    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.3        |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    reward               | -0.2168774 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 18.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 16384       |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017156754 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    approx_kl            | 0.017156754 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.00904     |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.00904     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 2.293914    |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 2.293914    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 35          |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019492887 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    approx_kl            | 0.019492887 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | 0.000787    |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | 0.000787    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 3.0802658   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 25.6        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | 3.0802658   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 220        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 93         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02947182 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.6      |\n",
      "|    explained_variance   | 0.033      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.25       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    reward               | -2.0188642 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 23.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 220        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 93         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02947182 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.6      |\n",
      "|    explained_variance   | 0.033      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.25       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    reward               | -2.0188642 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 23.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 22528       |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022794506 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    approx_kl            | 0.022794506 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.0088      |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.0088      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 1.1138003   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 31.8        |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 1.1138003   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 24576       |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022707373 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    approx_kl            | 0.022707373 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.00361     |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.00361     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | -1.5641013  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 33.5        |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | -1.5641013  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016617667 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    approx_kl            | 0.016617667 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.0307     |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.0307     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 0.67517805  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 26.4        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 0.67517805  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3786312.99\n",
      "total_reward: 2786312.99\n",
      "total_cost: 278770.88\n",
      "total_trades: 75467\n",
      "Sharpe: 0.878\n",
      "=================================\n",
      "day: 2766, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3786312.99\n",
      "total_reward: 2786312.99\n",
      "total_cost: 278770.88\n",
      "total_trades: 75467\n",
      "Sharpe: 0.878\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 130        |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02364533 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    approx_kl            | 0.02364533 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.8      |\n",
      "|    explained_variance   | 0.00194    |\n",
      "|    entropy_loss         | -41.8      |\n",
      "|    explained_variance   | 0.00194    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 15.4       |\n",
      "|    loss                 | 15.4       |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    reward               | -0.9305158 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 27.6       |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    reward               | -0.9305158 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 27.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021515558 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    approx_kl            | 0.021515558 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.000766    |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.000766    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | 0.5520945   |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | 0.5520945   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 21.9        |\n",
      "|    value_loss           | 21.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011968058 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    approx_kl            | 0.011968058 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.8        |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | -0.09539402 |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | -0.09539402 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 56.6        |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022887938 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    approx_kl            | 0.022887938 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.00153     |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.00153     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | 0.40820673  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 29          |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | 0.40820673  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 29          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.03778258   |\n",
      "|    clip_fraction        | 0.236        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.9        |\n",
      "|    explained_variance   | -0.00962     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    reward               | -0.026465945 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.03778258   |\n",
      "|    clip_fraction        | 0.236        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.9        |\n",
      "|    explained_variance   | -0.00962     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 29.3         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    reward               | -0.026465945 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 44.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024948593 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    approx_kl            | 0.024948593 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.5        |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | -0.14286092 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 25.9        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | -0.14286092 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026227301 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    approx_kl            | 0.026227301 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | -0.0085     |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | -0.0085     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 0.31888193  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 31.4        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 0.31888193  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4607162.05\n",
      "total_reward: 3607162.05\n",
      "total_cost: 270591.11\n",
      "total_trades: 74503\n",
      "Sharpe: 0.903\n",
      "=================================\n",
      "day: 2766, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4607162.05\n",
      "total_reward: 3607162.05\n",
      "total_cost: 270591.11\n",
      "total_trades: 74503\n",
      "Sharpe: 0.903\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017475348 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.00538    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -0.5897332  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017475348 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.00538    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -0.5897332  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 32.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023036756 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    approx_kl            | 0.023036756 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.001      |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.001      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.4        |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 1.3062679   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 56.4        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 1.3062679   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 56.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022200352 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.0246     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.3039812  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024543488 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.00141     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | 0.23752725  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022200352 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.0246     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    reward               | -0.3039812  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024543488 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.00141     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | 0.23752725  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 51.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028007515 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    approx_kl            | 0.028007515 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | -0.0159     |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | -0.0159     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.83        |\n",
      "|    loss                 | 9.83        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | 2.1975582   |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | 2.1975582   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 24          |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023847245 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    approx_kl            | 0.023847245 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.0127      |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.0127      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    reward               | 3.6167884   |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    reward               | 3.6167884   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 28.4        |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 251         |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032250814 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    approx_kl            | 0.032250814 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.3        |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.2645108  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 40.7        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.2645108  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4023946.98\n",
      "total_reward: 3023946.98\n",
      "total_cost: 265514.52\n",
      "total_trades: 73878\n",
      "Sharpe: 0.937\n",
      "=================================\n",
      "day: 2766, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4023946.98\n",
      "total_reward: 3023946.98\n",
      "total_cost: 265514.52\n",
      "total_trades: 73878\n",
      "Sharpe: 0.937\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020453373 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    approx_kl            | 0.020453373 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.00656     |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.00656     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.7        |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -1.1382695  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 34          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | -1.1382695  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 270        |\n",
      "|    total_timesteps      | 59392      |\n",
      "|    fps                  | 219        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 270        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02865621 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    approx_kl            | 0.02865621 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.5      |\n",
      "|    explained_variance   | 0.00341    |\n",
      "|    entropy_loss         | -42.5      |\n",
      "|    explained_variance   | 0.00341    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.64       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    reward               | 3.4097285  |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 18.8       |\n",
      "|    loss                 | 9.64       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    reward               | 3.4097285  |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 18.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 61440       |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021159753 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    approx_kl            | 0.021159753 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 0.8589097   |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 0.8589097   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 27.7        |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 63488       |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016729686 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    approx_kl            | 0.016729686 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00391     |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.00391     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -3.718235   |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -3.718235   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 82.3        |\n",
      "|    value_loss           | 82.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 65536       |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016758025 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    approx_kl            | 0.016758025 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.0139     |\n",
      "|    explained_variance   | -0.0139     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 1.5884396   |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 1.5884396   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 86          |\n",
      "|    value_loss           | 86          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 67584       |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013415829 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    approx_kl            | 0.013415829 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00286    |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | -0.00286    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 0.020533012 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 30.6        |\n",
      "|    loss                 | 14.3        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 0.020533012 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 30.6        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4040282.22\n",
      "total_reward: 3040282.22\n",
      "total_cost: 252691.76\n",
      "total_trades: 72746\n",
      "Sharpe: 0.972\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 316          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016931765  |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0282      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.4         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    reward               | -0.079709046 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 81.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 220        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03742979 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | -0.041     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.000573  |\n",
      "|    reward               | -8.211983  |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 29.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 220        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 334        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03477204 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | 0.0614     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.5       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.00887   |\n",
      "|    reward               | -4.594031  |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 43.5       |\n",
      "----------------------------------------\n",
      "day: 2766, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4040282.22\n",
      "total_reward: 3040282.22\n",
      "total_cost: 252691.76\n",
      "total_trades: 72746\n",
      "Sharpe: 0.972\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 219          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 316          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016931765  |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.0282      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.4         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    reward               | -0.079709046 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 81.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 220        |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 325        |\n",
      "|    total_timesteps      | 71680      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03742979 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | -0.041     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.9       |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.000573  |\n",
      "|    reward               | -8.211983  |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 29.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 220        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 334        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03477204 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.6      |\n",
      "|    explained_variance   | 0.0614     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 26.5       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.00887   |\n",
      "|    reward               | -4.594031  |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 43.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 343         |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028424982 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    approx_kl            | 0.028424982 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.4        |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.4110045   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 54.3        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 2.4110045   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032067165 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    approx_kl            | 0.032067165 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 70.8        |\n",
      "|    loss                 | 70.8        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 2.2201889   |\n",
      "|    reward               | 2.2201889   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 123         |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 220         |\n",
      "|    fps                  | 220         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013482265 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    approx_kl            | 0.013482265 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00193     |\n",
      "|    entropy_loss         | -42.7       |\n",
      "|    explained_variance   | 0.00193     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 191         |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | -9.319913   |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    reward               | -9.319913   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 282         |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 370         |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024031922 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    approx_kl            | 0.024031922 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0534      |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0534      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 28.1        |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -7.3460355  |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -7.3460355  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 91.2        |\n",
      "|    value_loss           | 91.2        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6492372.72\n",
      "total_reward: 5492372.72\n",
      "total_cost: 267209.28\n",
      "total_trades: 73851\n",
      "Sharpe: 1.031\n",
      "=================================\n",
      "day: 2766, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6492372.72\n",
      "total_reward: 5492372.72\n",
      "total_cost: 267209.28\n",
      "total_trades: 73851\n",
      "Sharpe: 1.031\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034239464 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    approx_kl            | 0.034239464 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00137    |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | -0.00137    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 61.9        |\n",
      "|    loss                 | 61.9        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -2.323761   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 148         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -2.323761   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 388         |\n",
      "|    time_elapsed         | 388         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034206137 |\n",
      "|    approx_kl            | 0.034206137 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    entropy_loss         | -42.8       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 99.8        |\n",
      "|    loss                 | 99.8        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 1.0796624   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 228         |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    reward               | 1.0796624   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 221        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 397        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01604093 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.0319     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 97.7       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00547   |\n",
      "|    reward               | -16.267452 |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 288        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 221        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 397        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01604093 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.9      |\n",
      "|    explained_variance   | 0.0319     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 97.7       |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00547   |\n",
      "|    reward               | -16.267452 |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 288        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 406         |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020398114 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    approx_kl            | 0.020398114 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.206      |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 41.6        |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.8554212   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 90.1        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.8554212   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 90.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 415         |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019474786 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    approx_kl            | 0.019474786 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00365    |\n",
      "|    entropy_loss         | -42.9       |\n",
      "|    explained_variance   | -0.00365    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 195         |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    reward               | -0.14699738 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031469822 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0205      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -0.40199456 |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    reward               | -0.14699738 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 279         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031469822 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0205      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -0.40199456 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 323         |\n",
      "|    value_loss           | 323         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 433         |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032338604 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    approx_kl            | 0.032338604 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    entropy_loss         | -43         |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 163         |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | -1.2207758  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 302         |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | -1.2207758  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 302         |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 55\n",
      "day: 2766, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5283078.54\n",
      "total_reward: 4283078.54\n",
      "total_cost: 253663.30\n",
      "total_trades: 72243\n",
      "Sharpe: 1.085\n",
      "end_total_asset: 5283078.54\n",
      "total_reward: 4283078.54\n",
      "total_cost: 253663.30\n",
      "total_trades: 72243\n",
      "Sharpe: 1.085\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 222       |\n",
      "|    iterations           | 48        |\n",
      "|    time_elapsed         | 442       |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0462926 |\n",
      "|    clip_fraction        | 0.418     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.1     |\n",
      "|    explained_variance   | 0.219     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 10.6      |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | -0.00287  |\n",
      "|    reward               | 1.7262672 |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 25.1      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 222       |\n",
      "|    iterations           | 48        |\n",
      "|    time_elapsed         | 442       |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0462926 |\n",
      "|    clip_fraction        | 0.418     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -43.1     |\n",
      "|    explained_variance   | 0.219     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 10.6      |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | -0.00287  |\n",
      "|    reward               | 1.7262672 |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 25.1      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030114053 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    approx_kl            | 0.030114053 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0897      |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0897      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.8        |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | -2.125436   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 65.8        |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | -2.125436   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 460         |\n",
      "|    time_elapsed         | 460         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026140358 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    approx_kl            | 0.026140358 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    entropy_loss         | -43.1       |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 129         |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 0.22006375  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 262         |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    reward               | 0.22006375  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 222        |\n",
      "|    fps                  | 222        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 469        |\n",
      "|    time_elapsed         | 469        |\n",
      "|    total_timesteps      | 104448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04365558 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    approx_kl            | 0.04365558 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0128     |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | 0.0128     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.6       |\n",
      "|    loss                 | 16.6       |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | 0.0042     |\n",
      "|    reward               | -0.4075587 |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 30.3       |\n",
      "|    policy_gradient_loss | 0.0042     |\n",
      "|    reward               | -0.4075587 |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 30.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 222        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 478        |\n",
      "|    total_timesteps      | 106496     |\n",
      "|    fps                  | 222        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 478        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03271871 |\n",
      "|    approx_kl            | 0.03271871 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.0105    |\n",
      "|    entropy_loss         | -43.2      |\n",
      "|    explained_variance   | -0.0105    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.56       |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.00424   |\n",
      "|    reward               | -2.6413572 |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 14         |\n",
      "|    loss                 | 5.56       |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.00424   |\n",
      "|    reward               | -2.6413572 |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 14         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 108544      |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029680468 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    approx_kl            | 0.029680468 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0444      |\n",
      "|    entropy_loss         | -43.2       |\n",
      "|    explained_variance   | 0.0444      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.66        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | 0.6296776   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18          |\n",
      "|    loss                 | 7.66        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    reward               | 0.6296776   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036384147 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0926      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | 6.5937066   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4820133.89\n",
      "total_reward: 3820133.89\n",
      "total_cost: 267903.49\n",
      "total_trades: 73864\n",
      "Sharpe: 1.126\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 222          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.034757257  |\n",
      "|    clip_fraction        | 0.4          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.4        |\n",
      "|    explained_variance   | 0.0115       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    reward               | -0.019091845 |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036384147 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.3       |\n",
      "|    explained_variance   | 0.0926      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    reward               | 6.5937066   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 39.9        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4820133.89\n",
      "total_reward: 3820133.89\n",
      "total_cost: 267903.49\n",
      "total_trades: 73864\n",
      "Sharpe: 1.126\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 222          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.034757257  |\n",
      "|    clip_fraction        | 0.4          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.4        |\n",
      "|    explained_variance   | 0.0115       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    reward               | -0.019091845 |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 222        |\n",
      "|    fps                  | 222        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 514        |\n",
      "|    time_elapsed         | 514        |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03942302 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    approx_kl            | 0.03942302 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.113      |\n",
      "|    entropy_loss         | -43.5      |\n",
      "|    explained_variance   | 0.113      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.74       |\n",
      "|    loss                 | 5.74       |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.00838   |\n",
      "|    reward               | 2.8159559  |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 13.3       |\n",
      "|    policy_gradient_loss | -0.00838   |\n",
      "|    reward               | 2.8159559  |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 13.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 523         |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042115115 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    approx_kl            | 0.042115115 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.74        |\n",
      "|    loss                 | 4.74        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | -1.4706585  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 15.6        |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    reward               | -1.4706585  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 222         |\n",
      "|    fps                  | 222         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 532         |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036098804 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    approx_kl            | 0.036098804 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0749      |\n",
      "|    entropy_loss         | -43.6       |\n",
      "|    explained_variance   | 0.0749      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.48        |\n",
      "|    loss                 | 8.48        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | 0.00212     |\n",
      "|    reward               | 0.95507294  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 23.4        |\n",
      "|    policy_gradient_loss | 0.00212     |\n",
      "|    reward               | 0.95507294  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 541         |\n",
      "|    time_elapsed         | 541         |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029672287 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    approx_kl            | 0.029672287 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0356      |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.0356      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.4        |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | -3.3792448  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 24.1        |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    reward               | -3.3792448  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 550         |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023580551 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    approx_kl            | 0.023580551 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    entropy_loss         | -43.7       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.9527205   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 25.2        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 0.9527205   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 65\n",
      "day: 2766, episode: 65\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4933999.05\n",
      "total_reward: 3933999.05\n",
      "total_cost: 211070.70\n",
      "total_trades: 68647\n",
      "Sharpe: 1.043\n",
      "end_total_asset: 4933999.05\n",
      "total_reward: 3933999.05\n",
      "total_cost: 211070.70\n",
      "total_trades: 68647\n",
      "Sharpe: 1.043\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 223        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 559        |\n",
      "|    total_timesteps      | 124928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03290446 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | -0.00323   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.4       |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    reward               | -1.8654158 |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 39.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 223        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 559        |\n",
      "|    total_timesteps      | 124928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03290446 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -43.8      |\n",
      "|    explained_variance   | -0.00323   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 18.4       |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    reward               | -1.8654158 |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 39.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 126976      |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040584378 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.000727    |\n",
      "|    reward               | -14.0597105 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 577         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023495222 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    approx_kl            | 0.040584378 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.8       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | 0.000727    |\n",
      "|    reward               | -14.0597105 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 577         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023495222 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0661      |\n",
      "|    explained_variance   | 0.0661      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    reward               | -4.852021   |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    reward               | -4.852021   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 66.1        |\n",
      "|    value_loss           | 66.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 586          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105444025 |\n",
      "|    clip_fraction        | 0.0884       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.9        |\n",
      "|    explained_variance   | 0.0933       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.6         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.00999     |\n",
      "|    reward               | -0.5415586   |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 76.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 586          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105444025 |\n",
      "|    clip_fraction        | 0.0884       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.9        |\n",
      "|    explained_variance   | 0.0933       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 53.6         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.00999     |\n",
      "|    reward               | -0.5415586   |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 76.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 595         |\n",
      "|    total_timesteps      | 133120      |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 595         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017914915 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    approx_kl            | 0.017914915 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0668      |\n",
      "|    entropy_loss         | -43.9       |\n",
      "|    explained_variance   | 0.0668      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 97.7        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -0.2976097  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 122         |\n",
      "|    loss                 | 97.7        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -0.2976097  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 604         |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015093021 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    approx_kl            | 0.015093021 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0469      |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.0469      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.7        |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | -0.7436517  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 41.7        |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    reward               | -0.7436517  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 613         |\n",
      "|    time_elapsed         | 613         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038015455 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    approx_kl            | 0.038015455 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    entropy_loss         | -44         |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.58        |\n",
      "|    loss                 | 9.58        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    reward               | 0.84581566  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 18.8        |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    reward               | 0.84581566  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4704049.97\n",
      "total_reward: 3704049.97\n",
      "total_cost: 216446.77\n",
      "total_trades: 68934\n",
      "Sharpe: 1.041\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 223        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 622        |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02167556 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.203      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.00662   |\n",
      "|    reward               | 1.0479084  |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 20.7       |\n",
      "----------------------------------------\n",
      "day: 2766, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4704049.97\n",
      "total_reward: 3704049.97\n",
      "total_cost: 216446.77\n",
      "total_trades: 68934\n",
      "Sharpe: 1.041\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 223        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 622        |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02167556 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.1      |\n",
      "|    explained_variance   | 0.203      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.00662   |\n",
      "|    reward               | 1.0479084  |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 20.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 631         |\n",
      "|    time_elapsed         | 631         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013408971 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    approx_kl            | 0.013408971 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.8        |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.514664    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 33.5        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 0.514664    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 640         |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014749024 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    approx_kl            | 0.014749024 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0648      |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.0648      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 47.9        |\n",
      "|    loss                 | 47.9        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | 1.9536883   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 126         |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    reward               | 1.9536883   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 649         |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022748869 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    approx_kl            | 0.022748869 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    entropy_loss         | -44.1       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.54701835  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 28.8        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 0.54701835  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 658         |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021114627 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    approx_kl            | 0.021114627 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.1        |\n",
      "|    loss                 | 37.1        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.09515029  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 74.4        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 0.09515029  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 74.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032678537 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    approx_kl            | 0.032678537 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    entropy_loss         | -44.2       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 81.6        |\n",
      "|    loss                 | 81.6        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | 0.00316     |\n",
      "|    reward               | -0.6158082  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 138         |\n",
      "|    policy_gradient_loss | 0.00316     |\n",
      "|    reward               | -0.6158082  |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 676         |\n",
      "|    time_elapsed         | 676         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042243246 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    approx_kl            | 0.042243246 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0212      |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.0212      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.7        |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.000238    |\n",
      "|    reward               | 1.3477116   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 45.5        |\n",
      "|    policy_gradient_loss | 0.000238    |\n",
      "|    reward               | 1.3477116   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5580513.65\n",
      "total_reward: 4580513.65\n",
      "total_cost: 254949.36\n",
      "total_trades: 72346\n",
      "Sharpe: 1.108\n",
      "=================================\n",
      "day: 2766, episode: 75\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5580513.65\n",
      "total_reward: 4580513.65\n",
      "total_cost: 254949.36\n",
      "total_trades: 72346\n",
      "Sharpe: 1.108\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 223         |\n",
      "|    fps                  | 223         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 685         |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053019773 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    approx_kl            | 0.053019773 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.037       |\n",
      "|    entropy_loss         | -44.3       |\n",
      "|    explained_variance   | 0.037       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.1        |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    reward               | 2.4438396   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 28.1        |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    reward               | 2.4438396   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 224        |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 694        |\n",
      "|    total_timesteps      | 155648     |\n",
      "|    fps                  | 224        |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 694        |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03489046 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    approx_kl            | 0.03489046 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0892     |\n",
      "|    entropy_loss         | -44.3      |\n",
      "|    explained_variance   | 0.0892     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.00466   |\n",
      "|    reward               | 2.2734673  |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 34.8       |\n",
      "|    loss                 | 11.6       |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.00466   |\n",
      "|    reward               | 2.2734673  |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 34.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 703         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031831257 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.000991   |\n",
      "|    reward               | 3.2917192   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 703         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031831257 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.000991   |\n",
      "|    reward               | 3.2917192   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 712         |\n",
      "|    time_elapsed         | 712         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034036446 |\n",
      "|    clip_fraction        | 0.413       |\n",
      "|    approx_kl            | 0.034036446 |\n",
      "|    clip_fraction        | 0.413       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0214      |\n",
      "|    entropy_loss         | -44.4       |\n",
      "|    explained_variance   | 0.0214      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.1        |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | 0.0111      |\n",
      "|    reward               | -1.7881999  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 54          |\n",
      "|    policy_gradient_loss | 0.0111      |\n",
      "|    reward               | -1.7881999  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 54          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 721         |\n",
      "|    time_elapsed         | 721         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031731352 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    approx_kl            | 0.031731352 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -3.2531247  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 25.9        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    reward               | -3.2531247  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 224        |\n",
      "|    fps                  | 224        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 730        |\n",
      "|    time_elapsed         | 730        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02624945 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    approx_kl            | 0.02624945 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0916     |\n",
      "|    entropy_loss         | -44.5      |\n",
      "|    explained_variance   | 0.0916     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 17.3       |\n",
      "|    loss                 | 17.3       |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.00336   |\n",
      "|    reward               | 0.4725667  |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 43         |\n",
      "|    policy_gradient_loss | -0.00336   |\n",
      "|    reward               | 0.4725667  |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 43         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 739         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040392525 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | 0.000117    |\n",
      "|    reward               | 0.5649284   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5465517.03\n",
      "total_reward: 4465517.03\n",
      "total_cost: 224710.04\n",
      "total_trades: 69480\n",
      "Sharpe: 1.094\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 739         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040392525 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | 0.000117    |\n",
      "|    reward               | 0.5649284   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5465517.03\n",
      "total_reward: 4465517.03\n",
      "total_cost: 224710.04\n",
      "total_trades: 69480\n",
      "Sharpe: 1.094\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 748         |\n",
      "|    time_elapsed         | 748         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01915839  |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    approx_kl            | 0.01915839  |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0465      |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.0465      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19          |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -0.10256647 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 46.8        |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -0.10256647 |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 757         |\n",
      "|    time_elapsed         | 757         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028615773 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    approx_kl            | 0.028615773 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.8        |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | 2.5952663   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 20.1        |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    reward               | 2.5952663   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 766         |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034651145 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    approx_kl            | 0.034651145 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    entropy_loss         | -44.5       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.7        |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | 0.00298     |\n",
      "|    reward               | 1.9947377   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 35.8        |\n",
      "|    policy_gradient_loss | 0.00298     |\n",
      "|    reward               | 1.9947377   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 775         |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03393028  |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    approx_kl            | 0.03393028  |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.000326   |\n",
      "|    reward               | -0.10029475 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 59.8        |\n",
      "|    policy_gradient_loss | -0.000326   |\n",
      "|    reward               | -0.10029475 |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 59.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 784          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.023579517  |\n",
      "|    clip_fraction        | 0.317        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.6        |\n",
      "|    explained_variance   | 0.0508       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | 0.00918      |\n",
      "|    reward               | -0.018860104 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 224          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 784          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.023579517  |\n",
      "|    clip_fraction        | 0.317        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.6        |\n",
      "|    explained_variance   | 0.0508       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | 0.00918      |\n",
      "|    reward               | -0.018860104 |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 40           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 793         |\n",
      "|    time_elapsed         | 793         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035429507 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    approx_kl            | 0.035429507 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.8333566  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 26.9        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -1.8333566  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 26.9        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 85\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5096287.76\n",
      "total_reward: 4096287.76\n",
      "total_cost: 209265.22\n",
      "total_trades: 68373\n",
      "Sharpe: 1.026\n",
      "=================================\n",
      "day: 2766, episode: 85\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5096287.76\n",
      "total_reward: 4096287.76\n",
      "total_cost: 209265.22\n",
      "total_trades: 68373\n",
      "Sharpe: 1.026\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023502296 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0958      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | -1.3032936  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023502296 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.0958      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    reward               | -1.3032936  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 811         |\n",
      "|    time_elapsed         | 811         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015064652 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    approx_kl            | 0.015064652 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.6        |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | -2.509935   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 47.8        |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    reward               | -2.509935   |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 47.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 820         |\n",
      "|    time_elapsed         | 820         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033270627 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    approx_kl            | 0.033270627 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0495      |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.0495      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.000597   |\n",
      "|    reward               | 0.50044847  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 37.5        |\n",
      "|    policy_gradient_loss | -0.000597   |\n",
      "|    reward               | 0.50044847  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 37.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 829         |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028491888 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    approx_kl            | 0.028491888 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    entropy_loss         | -44.7       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | 0.84206814  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 38.3        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | 0.84206814  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 838         |\n",
      "|    time_elapsed         | 838         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021639338 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    approx_kl            | 0.021639338 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.5        |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | 0.5824553   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 45.8        |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    reward               | 0.5824553   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 847         |\n",
      "|    time_elapsed         | 847         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016751226 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    approx_kl            | 0.016751226 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 37.2        |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 2.4995577   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 96.5        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    reward               | 2.4995577   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 856         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016497983 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.8690222   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5883317.12\n",
      "total_reward: 4883317.12\n",
      "total_cost: 207148.75\n",
      "total_trades: 67983\n",
      "Sharpe: 1.079\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 856         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016497983 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.8690222   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "day: 2766, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5883317.12\n",
      "total_reward: 4883317.12\n",
      "total_cost: 207148.75\n",
      "total_trades: 67983\n",
      "Sharpe: 1.079\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 865         |\n",
      "|    time_elapsed         | 865         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041185025 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    approx_kl            | 0.041185025 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    entropy_loss         | -44.9       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16          |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | 1.503433    |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 39          |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    reward               | 1.503433    |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 874         |\n",
      "|    total_timesteps      | 196608      |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 874         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032925293 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    approx_kl            | 0.032925293 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | -0.99500614 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 62.9        |\n",
      "|    loss                 | 29.2        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    reward               | -0.99500614 |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 62.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 883         |\n",
      "|    total_timesteps      | 198656      |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 883         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010160258 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    approx_kl            | 0.010160258 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | -1.4371961  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 224        |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 892        |\n",
      "|    total_timesteps      | 200704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02153448 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.5       |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.00829   |\n",
      "|    reward               | 2.9817822  |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 30.8       |\n",
      "----------------------------------------\n"
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | -1.4371961  |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 48.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 224        |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 892        |\n",
      "|    total_timesteps      | 200704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02153448 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -45        |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 16.5       |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.00829   |\n",
      "|    reward               | 2.9817822  |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 30.8       |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo,\n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=200000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1730813059610,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "cGNmES1ifp1O",
    "outputId": "e975c5dc-8d57-4e2c-88a6-55fd8044562a"
   },
   "outputs": [],
   "source": [
    "trained_ppo.save(config.TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOFOGFCPqmot"
   },
   "source": [
    "Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "DYpOmJMpqmou"
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1730813060118,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "kA3U0qJEqmov",
    "outputId": "f0d7437f-8c26-4bbc-e68c-3fdb974ca3a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1730813060119,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "nI1625Feqmov",
    "outputId": "d3bbbeed-ceea-46bd-e074-191b84c4b4c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>909194.253185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>911009.383914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>916962.469833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>928577.920684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>919340.924575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "183  2020-09-23  909194.253185\n",
       "184  2020-09-24  911009.383914\n",
       "185  2020-09-25  916962.469833\n",
       "186  2020-09-28  928577.920684\n",
       "187  2020-09-29  919340.924575"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEcli8bgqmow"
   },
   "source": [
    "Backtesting Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1730813060119,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "rKUbZkdjqmow",
    "outputId": "ea521dd0-7f0b-48f5-aa7a-b690454a091c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return         -0.106606\n",
      "Cumulative returns    -0.080659\n",
      "Annual volatility      0.422709\n",
      "Sharpe ratio          -0.056058\n",
      "Calmar ratio          -0.294170\n",
      "Stability              0.000500\n",
      "Max drawdown          -0.362396\n",
      "Omega ratio            0.989203\n",
      "Sortino ratio         -0.076674\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.107088\n",
      "Daily value at risk   -0.053350\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1730813060119,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "gVR-Z6mqqmox",
    "outputId": "286d4e4e-80e4-44b4-aab3-58b31eaace4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "Shape of DataFrame:  (188, 8)\n",
      "Annual return         -0.065199\n",
      "Cumulative returns    -0.049054\n",
      "Annual volatility      0.416030\n",
      "Sharpe ratio           0.046016\n",
      "Calmar ratio          -0.175803\n",
      "Stability              0.012240\n",
      "Max drawdown          -0.370862\n",
      "Omega ratio            1.009343\n",
      "Sortino ratio          0.062829\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.860019\n",
      "Daily value at risk   -0.052339\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\",\n",
    "        start = '2020-01-01',\n",
    "        end = '2020-09-30')\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1730813060119,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "xTYDqDq-qmox",
    "outputId": "050c18d4-417e-47f1-cd39-685604914641"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ppo</th>\n",
       "      <th>dji</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>9.994978e+05</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>9.999417e+05</td>\n",
       "      <td>1.002392e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>9.997660e+05</td>\n",
       "      <td>9.982119e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>1.000481e+06</td>\n",
       "      <td>1.003848e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-23</th>\n",
       "      <td>9.091943e+05</td>\n",
       "      <td>9.346322e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-24</th>\n",
       "      <td>9.110094e+05</td>\n",
       "      <td>9.364587e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>9.169625e+05</td>\n",
       "      <td>9.489818e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>9.285779e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>9.193409e+05</td>\n",
       "      <td>9.587147e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ppo           dji\n",
       "date                                  \n",
       "2020-01-02  1.000000e+06           NaN\n",
       "2020-01-03  9.994978e+05  1.000000e+06\n",
       "2020-01-06  9.999417e+05  1.002392e+06\n",
       "2020-01-07  9.997660e+05  9.982119e+05\n",
       "2020-01-08  1.000481e+06  1.003848e+06\n",
       "...                  ...           ...\n",
       "2020-09-23  9.091943e+05  9.346322e+05\n",
       "2020-09-24  9.110094e+05  9.364587e+05\n",
       "2020-09-25  9.169625e+05  9.489818e+05\n",
       "2020-09-28  9.285779e+05           NaN\n",
       "2020-09-29  9.193409e+05  9.587147e+05\n",
       "\n",
       "[188 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_ppo = df_account_value.set_index(df_account_value.columns[0])\n",
    "result = pd.DataFrame(\n",
    "    {\n",
    "        \"ppo\": df_result_ppo[\"account_value\"],\n",
    "        \"dji\": dji[\"close\"],\n",
    "    }\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1730813060119,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "zn0xNZUDqmox",
    "outputId": "c18e01a6-242f-4ab9-df16-7e7ef9752e64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQetK8uJfuFs"
   },
   "source": [
    "A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1730813060119,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "qAF3LFt3fwlV",
    "outputId": "8ff8f141-b8d8-4739-a97b-84fa9bd19f28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to results/a2c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natna\\miniforge3\\envs\\finRl\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = config.RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 568954,
     "status": "ok",
     "timestamp": 1730813629062,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "styOb2lIf3Wu",
    "outputId": "d20a84a4-0297-4c7e-f17d-75b9e00fb6af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 126          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.3        |\n",
      "|    explained_variance | 0.0855       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -33.9        |\n",
      "|    reward             | -0.018644849 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.967        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 126         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -85.2       |\n",
      "|    reward             | -0.26989207 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.65        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 126        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 21.3       |\n",
      "|    reward             | -1.7969959 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.38       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 126        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | 58.6       |\n",
      "|    reward             | -0.4503348 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.17       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 59        |\n",
      "|    reward             | 0.6550738 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.69      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | 0.334    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 39.8     |\n",
      "|    reward             | 2.207521 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.38     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | -0.0177     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 47.5        |\n",
      "|    reward             | -0.08229524 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 31         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0.0455     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 44.4       |\n",
      "|    reward             | 0.19633797 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.31       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | -0.0303     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 36.4        |\n",
      "|    reward             | -0.18739128 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 1.67        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | -0.0322   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 143       |\n",
      "|    reward             | 2.2978694 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 11.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.4    |\n",
      "|    explained_variance | -0.0238  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -26.6    |\n",
      "|    reward             | 2.005103 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4        |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -13.3     |\n",
      "|    reward             | 2.9423332 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.694     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 134         |\n",
      "|    reward             | -0.33774704 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 14.7        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0.0338     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 111        |\n",
      "|    reward             | -0.7307334 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 10.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -226      |\n",
      "|    reward             | 3.7476933 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 40.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 92.1      |\n",
      "|    reward             | 1.3849531 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 8.8       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 84.4     |\n",
      "|    reward             | 0.691854 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.24     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 155        |\n",
      "|    reward             | -2.3710213 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 22.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 157        |\n",
      "|    reward             | -1.1586894 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 16.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -285      |\n",
      "|    reward             | 4.7781963 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0.0421     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | -188       |\n",
      "|    reward             | -3.3069093 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 33.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 87         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 16.5       |\n",
      "|    reward             | -1.3376378 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.06       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | 126        |\n",
      "|    reward             | 0.18188399 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 12.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 95         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | 121        |\n",
      "|    reward             | 0.56550777 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 13.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 99         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | 167        |\n",
      "|    reward             | -1.7899404 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 24.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | -18.5      |\n",
      "|    reward             | -2.2628586 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 107        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -76.3      |\n",
      "|    reward             | 0.37216988 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 6.57       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 111        |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -491       |\n",
      "|    reward             | -6.1877747 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 202        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | -152       |\n",
      "|    reward             | 0.40913004 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 19.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 119        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 21.9       |\n",
      "|    reward             | 0.47357196 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 12.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | -0.00205   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | -38.5      |\n",
      "|    reward             | -3.6104586 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 127        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -65.2      |\n",
      "|    reward             | -2.1732647 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.44       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -158      |\n",
      "|    reward             | -4.258107 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 16.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 21.7      |\n",
      "|    reward             | 2.9699407 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.63      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 83.9      |\n",
      "|    reward             | -7.438669 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 142        |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0.0171     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | 53.8       |\n",
      "|    reward             | 0.26770645 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.71       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 85.4      |\n",
      "|    reward             | 0.5115145 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.8       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | 140        |\n",
      "|    reward             | -0.7936732 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 15.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -27.8     |\n",
      "|    reward             | -0.872657 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 115      |\n",
      "|    reward             | 4.68691  |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 17.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 1.08e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 16.1      |\n",
      "|    reward             | 0.9510701 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.13      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 126         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | -79.3       |\n",
      "|    reward             | -0.27066097 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 9           |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 126       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 78.5      |\n",
      "|    reward             | -3.811812 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.53      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 174        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | -7.37      |\n",
      "|    reward             | -2.0822947 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.86       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 1.53       |\n",
      "|    reward             | 0.43479815 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.76       |\n",
      "--------------------------------------\n",
      "day: 2514, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2106578.05\n",
      "total_reward: 1106578.05\n",
      "total_cost: 10616.21\n",
      "total_trades: 37965\n",
      "Sharpe: 0.469\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.7     |\n",
      "|    explained_variance | 0.452     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -50.6     |\n",
      "|    reward             | -1.462598 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.93      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 186        |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | -122       |\n",
      "|    reward             | -0.8889466 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 7.98       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | -7.93      |\n",
      "|    reward             | -0.9792017 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.08       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 202       |\n",
      "|    reward             | 2.1965184 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 25.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 61.2       |\n",
      "|    reward             | -1.1693689 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.95       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.8       |\n",
      "|    explained_variance | -5.52e-05   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | -76.2       |\n",
      "|    reward             | -0.01414926 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 5.49        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 206        |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | 56.1       |\n",
      "|    reward             | 0.80699503 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.9        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.9       |\n",
      "|    explained_variance | -2.24       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | 98          |\n",
      "|    reward             | -0.41062936 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 7.33        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 0.705       |\n",
      "|    reward             | -0.09624669 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.9      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 65.4       |\n",
      "|    reward             | -3.5214417 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.56       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.9     |\n",
      "|    explained_variance | 0.151     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 17.9      |\n",
      "|    reward             | 0.2371034 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.405     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 226        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -6.22      |\n",
      "|    reward             | 0.48928848 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 4.65       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -115      |\n",
      "|    reward             | -0.507884 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6.8       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -14.1     |\n",
      "|    reward             | -1.714109 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.206     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -3.62     |\n",
      "|    reward             | -2.986399 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.796     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | 9.18       |\n",
      "|    reward             | 0.28377628 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.348      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 246       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 4.6       |\n",
      "|    reward             | 1.026838  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.162     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | -135       |\n",
      "|    reward             | 0.25977516 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 254       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -266      |\n",
      "|    reward             | 2.048527  |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 44.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 258       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 50.1      |\n",
      "|    reward             | 1.5343491 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 5.1       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 262       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -48.5     |\n",
      "|    reward             | 1.0740918 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.77      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 266        |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 2.43       |\n",
      "|    reward             | -1.8206629 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.462      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 271       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -24.6     |\n",
      "|    reward             | 3.1274269 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 7.57        |\n",
      "|    reward             | -0.59449553 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 279        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 110        |\n",
      "|    reward             | -4.5663366 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 7.64       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | 3.31        |\n",
      "|    reward             | -0.84744936 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 287        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.1      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -37.6      |\n",
      "|    reward             | -2.2970583 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.731      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | 75.2        |\n",
      "|    reward             | -0.10335575 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 3.88        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 295       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 146       |\n",
      "|    reward             | 1.6328979 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 17.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 299        |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | 56.7       |\n",
      "|    reward             | 0.23032695 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | -77.2      |\n",
      "|    reward             | 0.43073338 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 3.94       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 307       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 20.2      |\n",
      "|    reward             | 1.5378315 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.673     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 311        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | -21.7      |\n",
      "|    reward             | -0.9294494 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 2.64       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 314        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -28        |\n",
      "|    reward             | -0.8637219 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.791      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 318       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 453       |\n",
      "|    reward             | 3.9634957 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 154       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 37.8        |\n",
      "|    reward             | -0.04481529 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 326       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 75.9      |\n",
      "|    reward             | 0.7319126 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 5.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 330      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 13       |\n",
      "|    reward             | -3.05642 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.566    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 334        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | -32.1      |\n",
      "|    reward             | -0.7853068 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.13       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 338       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -212      |\n",
      "|    reward             | 12.917028 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 43.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 342        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -56.7      |\n",
      "|    reward             | 0.07929226 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 1.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 346       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | 0.485     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 72.9      |\n",
      "|    reward             | 1.7425029 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.02      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 350       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 108       |\n",
      "|    reward             | -3.207751 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 6.58      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 125         |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 45          |\n",
      "|    reward             | -0.27220154 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 1.48        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 22.1     |\n",
      "|    reward             | -2.46154 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 16.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 362       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -92.7     |\n",
      "|    reward             | 1.8949244 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 5.7       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 366        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0.0228     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | 43.8       |\n",
      "|    reward             | -1.3488041 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 2.46       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 370        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | 2.18       |\n",
      "|    reward             | -0.5475696 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.625      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | -0.0861   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 88.4      |\n",
      "|    reward             | 1.2717767 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 7.98      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 378        |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | 92.1       |\n",
      "|    reward             | -5.0089564 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 15         |\n",
      "--------------------------------------\n",
      "day: 2514, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2787476.08\n",
      "total_reward: 1787476.08\n",
      "total_cost: 4352.29\n",
      "total_trades: 37453\n",
      "Sharpe: 0.686\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 382        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 1.07e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 13.9       |\n",
      "|    reward             | -1.0166157 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.263      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 386        |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 6.56e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | -74.6      |\n",
      "|    reward             | 0.31246972 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 5.65       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 390       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.2     |\n",
      "|    explained_variance | -0.0127   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 104       |\n",
      "|    reward             | 1.6456469 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.51      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 394        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 8.4        |\n",
      "|    reward             | 0.22673234 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.333      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 125        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 398        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0.015      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | -347       |\n",
      "|    reward             | -1.2786705 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 137        |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c,\n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1730813629062,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "yw89A8hkf_0E",
    "outputId": "5e849271-97f5-4475-82d7-f93d02ffdc96"
   },
   "outputs": [],
   "source": [
    "trained_a2c.save(config.TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpsb_srwxSeJ"
   },
   "source": [
    "Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "pbhgA-S2xSeJ"
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1730813629552,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "YKsJ4NO1xSeJ",
    "outputId": "e89a8649-9096-4fbe-ff5f-0f516d3b1578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1730813629553,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "32rJegIHxSeK",
    "outputId": "773a6dcb-7f45-4886-a773-9a4f3b3c6a14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>932457.358241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>935975.452659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>949245.242111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>965283.748893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>961955.772083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "183  2020-09-23  932457.358241\n",
       "184  2020-09-24  935975.452659\n",
       "185  2020-09-25  949245.242111\n",
       "186  2020-09-28  965283.748893\n",
       "187  2020-09-29  961955.772083"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SViEqNgCxSeK"
   },
   "source": [
    "Backtesting Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1730813629553,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "Ojev0r2pxSeK",
    "outputId": "dc6c8e32-0ae1-4652-fdb6-f5725557fcee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return         -0.050662\n",
      "Cumulative returns    -0.038044\n",
      "Annual volatility      0.399601\n",
      "Sharpe ratio           0.069960\n",
      "Calmar ratio          -0.141434\n",
      "Stability              0.000611\n",
      "Max drawdown          -0.358206\n",
      "Omega ratio            1.014689\n",
      "Sortino ratio          0.095153\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.858610\n",
      "Daily value at risk   -0.050234\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1730813629553,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "2bZAHxflxSeK",
    "outputId": "e44cced7-eb0d-41bf-f35f-03b9ba1f2063"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "Shape of DataFrame:  (188, 8)\n",
      "Annual return         -0.065199\n",
      "Cumulative returns    -0.049054\n",
      "Annual volatility      0.416030\n",
      "Sharpe ratio           0.046016\n",
      "Calmar ratio          -0.175803\n",
      "Stability              0.012240\n",
      "Max drawdown          -0.370862\n",
      "Omega ratio            1.009343\n",
      "Sortino ratio          0.062829\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.860019\n",
      "Daily value at risk   -0.052339\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\",\n",
    "        start = '2020-01-01',\n",
    "        end = '2020-09-30')\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1730813629553,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "NjpzZeMJxSeK",
    "outputId": "c9d1ae3b-170f-4fe1-d5c1-4a637e76a191"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a2c</th>\n",
       "      <th>dji</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>9.985980e+05</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>9.999666e+05</td>\n",
       "      <td>1.002392e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>9.986441e+05</td>\n",
       "      <td>9.982119e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>1.004843e+06</td>\n",
       "      <td>1.003848e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-23</th>\n",
       "      <td>9.324574e+05</td>\n",
       "      <td>9.346322e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-24</th>\n",
       "      <td>9.359755e+05</td>\n",
       "      <td>9.364587e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>9.492452e+05</td>\n",
       "      <td>9.489818e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>9.652837e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-29</th>\n",
       "      <td>9.619558e+05</td>\n",
       "      <td>9.587147e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     a2c           dji\n",
       "date                                  \n",
       "2020-01-02  1.000000e+06           NaN\n",
       "2020-01-03  9.985980e+05  1.000000e+06\n",
       "2020-01-06  9.999666e+05  1.002392e+06\n",
       "2020-01-07  9.986441e+05  9.982119e+05\n",
       "2020-01-08  1.004843e+06  1.003848e+06\n",
       "...                  ...           ...\n",
       "2020-09-23  9.324574e+05  9.346322e+05\n",
       "2020-09-24  9.359755e+05  9.364587e+05\n",
       "2020-09-25  9.492452e+05  9.489818e+05\n",
       "2020-09-28  9.652837e+05           NaN\n",
       "2020-09-29  9.619558e+05  9.587147e+05\n",
       "\n",
       "[188 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_a2c = df_account_value.set_index(df_account_value.columns[0])\n",
    "result = pd.DataFrame(\n",
    "    {\n",
    "        \"a2c\": df_result_a2c[\"account_value\"],\n",
    "        \"dji\": dji[\"close\"],\n",
    "    }\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1730813629553,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "Opz_OgDbxSeK",
    "outputId": "cd988cd3-4020-4414-8903-d8a1ff7b6c15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1730813629553,
     "user": {
      "displayName": "Natty Metekie",
      "userId": "06571578933818431366"
     },
     "user_tz": -240
    },
    "id": "K7P5-LrIzmuz",
    "outputId": "f61fd5f8-bf52-415e-af07-9df423777404"
   },
   "outputs": [],
   "source": [
    "result.plot()\n",
    "plt.savefig('results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta-Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natna\\miniforge3\\envs\\finRl\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n",
      "c:\\Users\\natna\\miniforge3\\envs\\finRl\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "trained_ddpg = model_ddpg.load(config.TRAINED_MODEL_DIR + \"/agent_ddpg\")\n",
    "model_ppo = agent.get_model(\"ppo\")\n",
    "trained_ppo = model_ppo.load(config.TRAINED_MODEL_DIR + \"/agent_ppo\", device='cpu')\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "trained_a2c = model_a2c.load(config.TRAINED_MODEL_DIR + \"/agent_a2c\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_predictions(model, environment):\n",
    "    return DRLAgent.DRL_prediction(\n",
    "        model=model,\n",
    "        environment = environment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m StockTradingEnv(df \u001b[38;5;241m=\u001b[39m train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menv_kwargs)\n\u001b[0;32m      3\u001b[0m ddpg_actions \u001b[38;5;241m=\u001b[39m get_agent_predictions(trained_ddpg, env)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mddpg_actions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "env = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "ddpg_actions = get_agent_predictions(trained_ddpg, env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1.000084e+06</td>\n",
       "      <td>84.128969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>9.997208e+05</td>\n",
       "      <td>-363.307129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1.001408e+06</td>\n",
       "      <td>1686.867521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1.000487e+06</td>\n",
       "      <td>-920.861481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>3.712038e+06</td>\n",
       "      <td>-3159.715149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>3.714289e+06</td>\n",
       "      <td>2250.711094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>3.727683e+06</td>\n",
       "      <td>13394.260773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>3.729718e+06</td>\n",
       "      <td>2035.292446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>3.705533e+06</td>\n",
       "      <td>-24184.996540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2515 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  account_value        reward\n",
       "0     2010-01-04   1.000000e+06      0.000000\n",
       "1     2010-01-05   1.000084e+06     84.128969\n",
       "2     2010-01-06   9.997208e+05   -363.307129\n",
       "3     2010-01-07   1.001408e+06   1686.867521\n",
       "4     2010-01-08   1.000487e+06   -920.861481\n",
       "...          ...            ...           ...\n",
       "2510  2019-12-23   3.712038e+06  -3159.715149\n",
       "2511  2019-12-24   3.714289e+06   2250.711094\n",
       "2512  2019-12-26   3.727683e+06  13394.260773\n",
       "2513  2019-12-27   3.729718e+06   2035.292446\n",
       "2514  2019-12-30   3.705533e+06 -24184.996540\n",
       "\n",
       "[2515 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value=ddpg_actions['account_value']\n",
    "df_account_value['reward'] = df_account_value['account_value'].diff().fillna(0.0)\n",
    "df_account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "day: 2514, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3961337.52\n",
      "total_reward: 2961337.52\n",
      "total_cost: 2314.48\n",
      "total_trades: 36892\n",
      "Sharpe: 0.946\n",
      "=================================\n",
      "hit end!\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "env = StockTradingEnv(df = train, **env_kwargs)\n",
    "ddpg_account_value, ddpg_actions = get_agent_predictions(trained_ddpg, env)\n",
    "ppo_account_value, ppo_actions = get_agent_predictions(trained_ppo, env)\n",
    "a2c_account_value, a2c_actions = get_agent_predictions(trained_a2c, env)\n",
    "\n",
    "combined_actions = pd.concat(\n",
    "    [ddpg_actions.add_suffix('_ddpg'), \n",
    "     ppo_actions.add_suffix('_ppo'),\n",
    "     a2c_actions.add_suffix('_a2c')], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_account_value['reward_ddpg'] = ddpg_account_value['account_value'].diff().fillna(0)\n",
    "ppo_account_value['reward_ppo']   = ppo_account_value['account_value'].diff().fillna(0)\n",
    "a2c_account_value['reward_a2c']   = a2c_account_value['account_value'].diff().fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72906"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_rewards = pd.concat(\n",
    "    [\n",
    "        ddpg_account_value['reward_ddpg'],\n",
    "        ppo_account_value['reward_ppo'],\n",
    "        a2c_account_value['reward_a2c']\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "ppo_actions.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract state features from the environment\n",
    "def extract_state_features(env):\n",
    "    states = []\n",
    "    for step in range(len(env.df)):\n",
    "        env.current_step = step\n",
    "        state = env._update_state()  # Get raw state vector\n",
    "        states.append(state)\n",
    "    \n",
    "    # Check the dimension of state\n",
    "    state_dim = env.observation_space.shape[0]  # Extract number of state features\n",
    "    columns = [f\"feature_{i}\" for i in range(state_dim)]  # Create column names\n",
    "\n",
    "    return pd.DataFrame(states, columns=columns)\n",
    "\n",
    "state_features = extract_state_features(env)\n",
    "\n",
    "# Combine actions and states into training data for the meta-policy\n",
    "# meta_input = pd.concat([combined_actions, state_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df_account_value.pct_change().fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "finRl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
