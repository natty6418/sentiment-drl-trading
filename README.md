# Sentiment-Aware Deep Reinforcement Learning Ensemble for Algorithmic Trading

This repository contains the implementation and evaluation of an ensemble deep reinforcement learning (DRL) pipeline for algorithmic stock trading. The system integrates both sentiment analysis (from Twitter/X and Alpha Vantage news) and technical indicators (RSI, MACD) to improve trading decisions in real-time market environments.

## ğŸš€ Project Overview

Traders often face difficulties synthesizing sentiment and technical signals effectively, particularly in volatile markets. Our project addresses this challenge by proposing a multimodal DRL architecture that enhances both profitability and risk management.

AY: 2024â€“2025, NYU Abu Dhabi Engineering Capstone

## ğŸ§  Architecture

We trained and combined the following DRL agents:

- **TD3 (Twin Delayed Deep Deterministic Policy Gradient)**
- **PPO (Proximal Policy Optimization)**
- **A2C (Advantage Actor-Critic)**

Three ensemble strategies were developed:

1. **Knowledge Distillation:** Averages the actions of experts to train a student network.
2. **Stacked RL:** Uses a meta-agent to select the most appropriate expert.
3. **Mixture of Experts:** Learns to combine expert actions using weighted averages.

These were fused into a unified action vector for live trading decisions.

## ğŸ“Š Results

- Ensemble models consistently outperformed individual agents and traditional baselines.
- Enhanced stability with reduced drawdowns and volatility.
- Supports shorting, enabling effectiveness in both bull and bear markets.
- Outperformed benchmarks during market stress scenarios (e.g., 2025 Tarif Meltdown).

## ğŸ§ª Testing and Evaluation

- Portfolio performance comparisons
- Risk-aware metrics (Sharpe Ratio, Drawdown)
- Real-world testing with historical stock data and real-time sentiment feeds

## âš™ï¸ Constraints

### Technical
- Minimum GPU memory: 16 GB (optimal: 32â€“64 GB)
- Limited access to high-quality real-time sentiment data

### Non-Technical
- Strict academic timeline for experiments
- Relied on open datasets and models for cost-effectiveness

## ğŸ“¦ Dependencies

> Will vary based on your implementation, but generally:

- Python 3.8+
- PyTorch / TensorFlow
- OpenAI Gym
- FinRL / Stable Baselines3
- Twitter API / Alpha Vantage API

## ğŸ“ Project Structure

```text
.
â”œâ”€â”€ AlphaVantage.py                 # Script for fetching news sentiment using Alpha Vantage API
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ dow30_monthly_news_sentiment.csv  # Preprocessed sentiment scores
â”‚   â””â”€â”€ merged_df.csv                      # Combined sentiment and stock data
â”œâ”€â”€ fineTunning/
â”‚   â”œâ”€â”€ finetuned_model/           # Directory for saved fine-tuned models
â”‚   â”œâ”€â”€ fineTunning.py             # Script to fine-tune language model
â”‚   â”œâ”€â”€ infer.ipynb                # Inference notebook for sentiment analysis
â”‚   â”œâ”€â”€ infer.py                   # Script for batch inference
â”‚   â”œâ”€â”€ requirements.txt           # Dependencies for fine-tuning
â”‚   â””â”€â”€ run_finetuning.slurm       # SLURM script for remote training
â”œâ”€â”€ Meta Policy.ipynb              # Notebook for ensemble meta-policy strategy
â”œâ”€â”€ Trading Bot.ipynb              # Main bot logic with evaluation and strategy switching
â”œâ”€â”€ requirements.txt               # Main project dependencies
â””â”€â”€ trained_models/
    â”œâ”€â”€ agent_a2c.zip
    â”œâ”€â”€ agent_a2c_sentiment.zip
    â”œâ”€â”€ agent_ddpg.zip
    â”œâ”€â”€ agent_ddpg_sentiment.zip
    â”œâ”€â”€ agent_ppo.zip
    â”œâ”€â”€ agent_ppo_sentiment.zip
    â”œâ”€â”€ agent_td3.zip
    â”œâ”€â”€ agent_td3_sentiment.zip
    â””â”€â”€ ppo_moe_gating_sb3.zip
```

## ğŸ“Œ Acknowledgments

Special thanks to our advisors and mentors for their support and guidance:

- Dr. Muhammad Abdullah Hanif  
- Dr. Muhammad Shafique  
- Dr. Pradeep George

## ğŸ“œ License

This project is for educational and research purposes. Licensing terms can be added based on your institutional or personal preference.


